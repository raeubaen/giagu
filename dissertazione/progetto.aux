\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\citation{Kadanoff2009}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{onsager}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Modello di Ising}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{metropolis-hastings}
\citation{dwave}
\citation{nphard}
\citation{quantumannealing}
\citation{quantumannealing}
\citation{quantumannealing}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Configurazioni, rispettivamente, ordinate, critiche e disordinate del modello semplificato.\relax }}{4}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Simulazione attraverso l'algoritmo di Metropolis}{4}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Approfondimento: applicazioni computazionali}{4}{section.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Esempi di associazione tra funzioni logiche e energia dei reticoli \cite  {quantumannealing}\relax }}{5}{table.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Learning}{6}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduzione alle Reti Neurali}{6}{section.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Schematizzazione tramite un grafo di una rete neurale composta da percettroni.\relax }}{6}{figure.caption.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Schematizzazione tramite un grafo di una rete feedforward.\relax }}{7}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Formalismo matematico}{7}{section.3.2}\protected@file@percent }
\newlabel{attivazioni}{{3.2}{7}{Formalismo matematico}{equation.3.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Discesa lungo il gradiente}{7}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Backpropagation}{8}{section.3.4}\protected@file@percent }
\citation{nielsenneural}
\citation{stylegan}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Reti GAN}{10}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Minimax GAN}{10}{section.4.1}\protected@file@percent }
\citation{Nash48}
\citation{manypathsgan}
\citation{goodfellowgan}
\citation{manypathsgan}
\citation{manypathsgan}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Non-saturating GAN}{11}{section.4.2}\protected@file@percent }
\newlabel{Non-saturating GAN}{{4.2}{11}{Non-saturating GAN}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Confronto tra non-saturating e minimax loss nel caso gaussiano 1D \cite  {manypathsgan}. Per l'output del discriminatore $D(x)$ si \IeC {\`e} supposto un andamento sigmoideo, dal quale si deduce il comportamento delle loss.\relax }}{12}{figure.caption.6}\protected@file@percent }
\citation{net2vis}
\citation{net2vis}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Sviluppo della DCGAN}{13}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Dataset}{13}{section.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Visualizzazione delle suddette caratteristiche del dataset\relax }}{13}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{difetti}{{5.1}{13}{Visualizzazione delle suddette caratteristiche del dataset\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Topologia delle reti}{13}{section.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces ...}}{14}{figure.caption.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Struttura del generatore. In input vi sono un vettore di dimensione 10 ed il vettore random di dimensione 128.\relax }}{14}{figure.caption.9}\protected@file@percent }
\citation{adam}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Struttura del regressore.\relax }}{15}{figure.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Training schedule}{15}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Caso ideale}{15}{subsection.5.3.1}\protected@file@percent }
\newlabel{Caso ideale}{{5.3.1}{15}{Caso ideale}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Fasi del training}{15}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Processing post-training}{16}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Risultati}{17}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces 100 diverse configurazioni generate dalla GAN. I campioni sulla stessa colonna corrispondono alla stessa classe di temperatura, che aumenta da sinistra a destra.\relax }}{17}{figure.caption.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Confronto tra campioni fake ed originali dello scatter plot con magnetizzazione vs. temperatura per 10k configurazioni.\relax }}{18}{figure.caption.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Confronto tra l'istogramma della magnetizzazione dei campioni fake e degli originali.\relax }}{18}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Deployment in JS}{19}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{reference}
\bibdata{bib}
\bibcite{Kadanoff2009}{1}
\bibcite{onsager}{2}
\bibcite{metropolis-hastings}{3}
\bibcite{dwave}{4}
\bibcite{nphard}{5}
\bibcite{quantumannealing}{6}
\bibcite{nielsenneural}{7}
\bibcite{stylegan}{8}
\bibcite{Nash48}{9}
\bibcite{manypathsgan}{10}
\bibcite{goodfellowgan}{11}
\bibcite{net2vis}{12}
\bibcite{adam}{13}
\bibcite{reference}{14}
\bibstyle{unsrt}
