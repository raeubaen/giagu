{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB_RL_LC7_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raeubaen/ml/blob/master/NB_RL_LC7_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pjdgzVgjxqXB"
      },
      "source": [
        "# Uso di OpenAI Gym e implementazione di smplici modelli di RL \n",
        "\n",
        "### Informazioni ###\n",
        "\n",
        "scopo: familiarizzare con lo sviluppo e utilizzo di semplici strumenti di Deep Reinfrocement Learning\n",
        "\n",
        "Un sistema di RL è costituito da un agente (la rete neurale) e un ambiente (environement) che interagiscono. \n",
        "\n",
        "> ambiente -> stato -> agente <p>\n",
        "> agente -> azione -> ambiente <p>\n",
        "> ambiente -> nuovo stato + reward -> agente <p>\n",
        "> ...\n",
        "\n",
        "Con metodi di trial&error l'agente cerca di migliorare le sue azioni sull'ambiente in modo da massimizzare in qualche modo il reward totale.\n",
        "\n",
        "DL tool: tensorflow/keras + OpenAI Gym\n",
        "\n",
        "### Modelli e task ###\n",
        "\n",
        "1.   Actor-Critic RL applicato all'ambiente simulato ***CartPole-V0***\n",
        "2.   Deep Q-Learning applicato all'ambiente simulato ***MountainCar-v0***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uJI9r-m7lJD",
        "colab_type": "text"
      },
      "source": [
        "## OpenAI gym\n",
        "\n",
        "[Gym](http://gym.openai.com/): toolkit per siviluppare ambienti simulati per studi di RL. \n",
        "\n",
        "---\n",
        "\n",
        "### CartPole-V0\n",
        "\n",
        "Environement simulato prodotto da OpenAI gym, in cui un asta è attaccata ad un carrello che si muove a destra o sinistra su un binario in assenza di attrito. L'agente deve applicare una forza per muovere il carrello, e deve apprendere a far rimanere l'asta in equilibrio senza cadere. \n",
        "\n",
        "[Descrizione dettagliata](http://gym.openai.com/docs/)\n",
        "\n",
        "**Spazio delle azioni:** discreto e di dimensione 2: accelerare left (0), accelerare right (1)\n",
        "\n",
        "**Ossevabile:** numpy 1D array di dimensione 4: cart's horizontal position (0.0 == centro) , velocity, angolo di inclinazione dell'asta (0.0 == verticale), velocità angolare dell'asta.\n",
        "\n",
        "**Reward:** 1 per ogni step fatto \n",
        "\n",
        "**Stato di partenza:** valori random in [-0.05..0.05]\n",
        "\n",
        "**Termine di un episodio:** angolo >= 12 gradi, abs(posizione) > 2.4 *0 è il centro), oppure >= 200 step\n",
        "\n",
        "---\n",
        "\n",
        "### MountainCar-v0\n",
        "\n",
        "Environement simulato prodotto da OpenAI gym, in cui un asta è attaccata ad un carrello che si muove a destra o sinistra su un binario in assenza di attrito. L'agente deve applicare una forza per muovere il carrello, e deve apprendere a far rimanere l'asta in equilibrio senza cadere. \n",
        "\n",
        "[Descrizione dettagliata](http://gym.openai.com/envs/#classic_control)\n",
        "\n",
        "**Spazio delle azioni:** discreto e di dimensione 3: accelerare left (0), non accelerare (1), accelerare right (2)\n",
        "\n",
        "**Ossevabile:** numpy 1D array di dimensione 2: car's position, velocity\n",
        "\n",
        "**Reward:** 0 se l'agente rioesce a ragiungere la posizione 0.5 in cima alla collina, -1 se la posizione è inferiore a 0.5\n",
        "\n",
        "**Stato di partenza:** posizione random in [-0.6,-0.4] (nota: -0.5 è il minimo), v=0\n",
        "\n",
        "**Termine di un episodio:** posizione >= 0.5 oppure >= 200 step\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LE0sGFaPxqXF"
      },
      "source": [
        "## Setup per visualizzazione\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huXlvfvG5-sf",
        "colab_type": "code",
        "outputId": "45383f22-a010-4fe8-bfe6-f365e6ccdd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "!apt-get install -y xvfb x11-utils\n",
        "!pip install pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 43 not upgraded.\n",
            "Need to get 993 kB of archives.\n",
            "After this operation, 2,977 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
            "Fetched 993 kB in 1s (1,514 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading https://files.pythonhosted.org/packages/69/ec/8221a07850d69fa3c57c02e526edd23d18c7c05d58ed103e3b19172757c1/PyVirtualDisplay-0.2.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.6/dist-packages (3.1.5)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/3c/f42a62b7784c04b20f8b88d6c8ad04f4f20b0767b721102418aad94d8389/PyOpenGL-accelerate-3.1.5.tar.gz (538kB)\n",
            "\u001b[K     |████████████████████████████████| 542kB 13.0MB/s \n",
            "\u001b[?25hCollecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp36-cp36m-linux_x86_64.whl size=1593670 sha256=be638052ec158dfdb7eb4abb23b93475794b7ce45fee5b1be45412b5f21b6903\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/21/77/99670ceca25fddb3c2b60a7ae44644b8253d1006e8ec417bcc\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay, PyOpenGL-accelerate\n",
            "Successfully installed EasyProcess-0.3 PyOpenGL-accelerate-3.1.5 pyvirtualdisplay-0.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkQQFEia6Q9j",
        "colab_type": "code",
        "outputId": "3d13d256-5c37-40c3-c727-5d75d7cb1378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pyvirtualdisplay\n",
        "\n",
        "_display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "_ = _display.start()\n",
        "\n",
        "!echo $DISPLAY"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":1001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU5XjN8q6lL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfcn_sLeRhjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#funzione comoda per graficare l'andamento del training del modello actor-critic\n",
        "def plot_results(values, title=''):   \n",
        "    # Update the window after each episode\n",
        "    display.clear_output(wait=True)\n",
        "    \n",
        "    # Define the figure\n",
        "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
        "    f.suptitle(title)\n",
        "    ax[0].plot(values, label='score per run')\n",
        "    ax[0].axhline(195, c='red',ls='--', label='goal')\n",
        "    ax[0].set_xlabel('Episodes')\n",
        "    ax[0].set_ylabel('Reward')\n",
        "    #ax[0].set_ylim([0,200]) \n",
        "    x = range(len(values))\n",
        "    ax[0].legend()\n",
        "    # Calculate the trend\n",
        "    try:\n",
        "        z = np.polyfit(x, values, 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax[0].plot(x,p(x),\"--\", label='trend')\n",
        "    except:\n",
        "        print('')\n",
        "    \n",
        "    # Plot the histogram of results\n",
        "    ax[1].hist(values[-50:])\n",
        "    ax[1].axvline(195, c='red', label='goal')\n",
        "    ax[1].set_xlabel('Scores per Last 50 Episodes')\n",
        "    ax[1].set_ylabel('Frequency')\n",
        "    ax[1].legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXskFktcIwLF",
        "colab_type": "text"
      },
      "source": [
        "### Algoritmo Dummy\n",
        "\n",
        "iniziamo con analizzare quali sono le prestazioni ottenibili facendo delle azioni random "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O03hbUpGqZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inizalizziamo il nostro envioronment \n",
        "seed = 1234"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZTDLTwwI8l1",
        "colab_type": "code",
        "outputId": "af6fcc1a-fb09-4770-b7bb-44c8d32be933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")  # Create the environment\n",
        "env.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1234]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma_J7hRAizGy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFkm9lTTJ6mW",
        "colab_type": "code",
        "outputId": "1e62a83b-bbc1-4430-8b8f-ad553575a0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Movimenti random\n",
        "\n",
        "# Random Policy\n",
        "\n",
        "state = env.reset() # si inizalizza il cart\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "done = False\n",
        "i = 0\n",
        "while not done:\n",
        "    action = env.action_space.sample()  #come azioni si prende un campionamento casuale dello spazio delle azioni possibili\n",
        "    img.set_data(env.render(mode='rgb_array')) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    state, reward, done, _ = env.step(action) #si applica l'azione e si ottiene il nuovo stato e il reward\n",
        "    i = i + 1\n",
        "env.close()\n",
        "print('runs for: %i steps' %(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runs for: 14 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwkvb7gbQu3P",
        "colab_type": "code",
        "outputId": "fcf9931b-115e-40c1-e00a-78aafc1e4160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "# giriamo 150 episodi e per oguno calcoliamo il reward e grafichiamo per vedere se ci sono trend \n",
        "# che indichino un qualche tipo di apprendimento ... (ovviamente non ci aspettiamo nulla)\n",
        "episodes = 150\n",
        "results = []  \n",
        "\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False \n",
        "    total = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        state, reward, done, _ = env.step(action) \n",
        "        total += reward \n",
        "    results.append(total)\n",
        "    plot_results(results,title='Random Strategy')\n",
        "    env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e32ed78b9645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Random Strategy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-3f6fd479326d>\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(values, title)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                             print_method, dpi=dpi, orientation=orientation),\n\u001b[1;32m   2078\u001b[0m                         draw_disabled=True)\n\u001b[0;32m-> 2079\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegendPatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'legend'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mbbox_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \"\"\"\n\u001b[1;32m    342\u001b[0m         width, height, xdescent, ydescent, offsets = self.get_extent_offsets(\n\u001b[0;32m--> 343\u001b[0;31m                                                         renderer)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdescent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydescent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_extent_offsets\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         whd_list = [c.get_extent(renderer)\n\u001b[0;32m--> 535\u001b[0;31m                     for c in self.get_visible_children()]\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwhd_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         whd_list = [c.get_extent(renderer)\n\u001b[0;32m--> 535\u001b[0;31m                     for c in self.get_visible_children()]\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwhd_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Return a tuple ``width, height, xdescent, ydescent`` of the box.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extent_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_extent_offsets\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         whd_list = [c.get_extent(renderer)\n\u001b[0;32m--> 461\u001b[0;31m                     for c in self.get_visible_children()]\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mwhd_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhd_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         whd_list = [c.get_extent(renderer)\n\u001b[0;32m--> 461\u001b[0;31m                     for c in self.get_visible_children()]\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mwhd_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhd_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Return a tuple ``width, height, xdescent, ydescent`` of the box.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extent_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_extent_offsets\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mxoffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxoffsets\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mxdescent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         return (width + 2 * pad, height + 2 * pad,\n\u001b[0m\u001b[1;32m    563\u001b[0m                 \u001b[0mxdescent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydescent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 list(zip(xoffsets, yoffsets)))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cDyHEN2K3Lz",
        "colab_type": "text"
      },
      "source": [
        "### Algoritmo Basilare\n",
        "\n",
        "Ora provimo ad implementare un algoritmo basato su regole di buon senso rispetto al problema: per esempio se l'asta si inclina verso destra ci muoviamo a destra se si inclina verso sininsta ci muoviamo a sinistra "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY7dl_3gJJIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")  # Create the environment\n",
        "env.seed(seed)\n",
        "\n",
        "# Simple Policy\n",
        "def simple_policy(obs):\n",
        "    angle = obs[2]\n",
        "    return 0 if angle < 0 else 1\n",
        "\n",
        "state = env.reset()\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "done = False\n",
        "i = 0\n",
        "while not done:\n",
        "    action = simple_policy(state)\n",
        "    img.set_data(env.render(mode='rgb_array')) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    state, reward, done, _ = env.step(action) \n",
        "    i = i + 1   \n",
        "env.close()\n",
        "print('run for: %i steps' %(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6neXplu6UWd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# giriamo 150 episodi e per oguno calcoliamo il reward e grafichiamo per vedere se ci sono trendo\n",
        "episodes = 150\n",
        "results = []  \n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False \n",
        "    total = 0\n",
        "    while not done:\n",
        "        action = simple_policy(state)\n",
        "        state, reward, done, _ = env.step(action) \n",
        "        total += reward \n",
        "    results.append(total)\n",
        "    plot_results(results,title='Simple Strategy')\n",
        "    env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zLdh7wCNxqXE"
      },
      "source": [
        "### Actor Critic Method\n",
        "\n",
        "Algoritmo classico di RL di tipo Policy Gradient. In questo tipo di algoritmi si cerca direttamente di ottimizzare l'agente rispetto al policy space, modellando con un DNN le probabilità associate ad ogni azione da raccomandare.\n",
        "\n",
        "Nell'agoritmo Actor-Critic (AC), l'agente è costituito da due entità separate: \n",
        "1. un attore (**actor**) che fornisce una rappresentazione della policy: assegnare un set di probabilità ad ogni azione possibile\n",
        "2. un critico (**critic**) che non è altro che una value function, cioè una funzione dello stato che stima la somma di tutti i rewards che ci si aspetta ricevere nel futuro\n",
        "\n",
        "Il critico apprende quanto bene l'attore (la policy) stà performando e sfrutta questa informazione per migliorare la policy stessa. Il miglioramento è ottenuto tramite Gradient Policy, cioè aggiornando la policy (l'attore) in modo da massimizzarne le stime della value function del critico, in parole diverse l'agente è addestrato in modo che le azioni raccomandate dall'attore massimizzano i reward futuri stimati dal critico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FBNggMxpxqXK"
      },
      "source": [
        "## Implementazione della rete neurale\n",
        "\n",
        "Costruiamo una semplice rete che apprende due funzioni:\n",
        "\n",
        "1. Actor: prende in input lo state e ritorna un volare di probabilità per ogni azione dell'action space \n",
        "2. Critic: prende in input lo state e ritorna la stima del reward totale (scontato) atteso nel futuro \n",
        "\n",
        "Si può fare con due reti separate, ma visto che l'input è lo stesso nell'implementazione usaremo per comodità e compattezza un layer iniziale shared \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TC9OADzTxqXL",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")  # Create the environment\n",
        "env.seed(seed)\n",
        "\n",
        "# Modello Actor-Critic \n",
        "num_inputs = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.n\n",
        "num_hidden = 128\n",
        "\n",
        "inputs = layers.Input(shape=(num_inputs,))\n",
        "common = layers.Dense(num_hidden, activation=\"relu\")(inputs)\n",
        "action = layers.Dense(num_actions, activation=\"softmax\")(common)\n",
        "critic = layers.Dense(1)(common)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=[action, critic])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S2H4OwcExqXP"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2c2ywVurxqXP",
        "outputId": "e1ea4179-fe89-49b7-ec9d-71bfae457010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        }
      },
      "source": [
        "# optmizer e Loss\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "huber_loss = keras.losses.Huber() #una approssimazione intermedia tra MAE e MSE\n",
        "\n",
        "# Parametri\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "max_steps_per_episode = 10000\n",
        "eps = np.finfo(np.float32).eps.item() # numero più piccolo per cui 1.0 + eps != 1.0\n",
        "\n",
        "# container utili\n",
        "action_probs_history = []\n",
        "critic_value_history = []\n",
        "rewards_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "\n",
        "results = []\n",
        "results_rr = []\n",
        "\n",
        "while True:  # Run until solved\n",
        "    state = env.reset()  #inzializza l'environment \n",
        "    episode_reward = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            state = tf.convert_to_tensor(state)\n",
        "            state = tf.expand_dims(state, 0) #aggiunge una dimensione (4) -> (1,4) per tf/keras\n",
        "\n",
        "            # dato lo stato la rete predice le probabilità delle azioni e stima i futuri rewards \n",
        "            action_probs, critic_value = model(state)\n",
        "            critic_value_history.append(critic_value[0, 0])\n",
        "\n",
        "            # calcola la nuova action sulla base delle probabilità\n",
        "            action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n",
        "            action_probs_history.append(tf.math.log(action_probs[0, action]))\n",
        "\n",
        "            # applica la nuova azione\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            rewards_history.append(reward)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "\n",
        "        # aggiorna il running reward \n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "        # calcolo valore atteso per il reward (i.e. le label del critic)\n",
        "        # - At each timestep what was the total reward received after that timestep\n",
        "        # - Rewards in the past are discounted by multiplying them with gamma\n",
        "        # - These are the labels for our critic\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        # Normalizzazione\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "        returns = returns.tolist()\n",
        "\n",
        "        # Calcolo delle loss per l'attore e per il critico \n",
        "        history = zip(action_probs_history, critic_value_history, returns)\n",
        "        actor_losses = []\n",
        "        critic_losses = []\n",
        "        for log_prob, value, ret in history:\n",
        "    \n",
        "            # per ogni valore nell'history il critico aveva stimato di avere in futuro un total reward pari a \"value\"\n",
        "            # noi abbiamo intrapreso una data azione con log(prob) = log_prob e abbiamo ricevuto il reward pari a \"ret\"\n",
        "           \n",
        "            # dobbiamo aggiornare l'attore in modo che predica con maggiore probabilità un'azione che porti a più alti \n",
        "            # reward rispetto alle stime del critico \n",
        "\n",
        "            diff = ret - value\n",
        "            actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            # dobbiamo aggornare il critico in modo che predica una migliore stima dei total reward futuri\n",
        "            critic_losses.append(\n",
        "                huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss_value = sum(actor_losses) + sum(critic_losses)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Clear the loss and reward history\n",
        "        action_probs_history.clear()\n",
        "        critic_value_history.clear()\n",
        "        rewards_history.clear()\n",
        "\n",
        "    # salva dettagli per monitorare il tutto + printout\n",
        "    episode_count += 1\n",
        "    results_rr.append(running_reward)\n",
        "    results.append(episode_reward)\n",
        "    plot_results(results,title='GP Actor-Critic Strategy')\n",
        "    \n",
        "    if running_reward > 195:  # Condizione per cui la task è considerata risolta\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "#printout dei risultati\n",
        "for episodio in range(episode_count):\n",
        "    if episodio % 10 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(results_rr[episodio], episodio))\n",
        "\n",
        "    if results_rr[episodio] > 195:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episodio))\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Solved at episode 233!\n",
            "running reward: 1.30 at episode 0\n",
            "running reward: 12.61 at episode 10\n",
            "running reward: 22.92 at episode 20\n",
            "running reward: 29.49 at episode 30\n",
            "running reward: 31.57 at episode 40\n",
            "running reward: 59.93 at episode 50\n",
            "running reward: 77.11 at episode 60\n",
            "running reward: 85.68 at episode 70\n",
            "running reward: 126.73 at episode 80\n",
            "running reward: 150.26 at episode 90\n",
            "running reward: 169.19 at episode 100\n",
            "running reward: 181.55 at episode 110\n",
            "running reward: 176.03 at episode 120\n",
            "running reward: 177.75 at episode 130\n",
            "running reward: 172.09 at episode 140\n",
            "running reward: 182.48 at episode 150\n",
            "running reward: 189.51 at episode 160\n",
            "running reward: 187.43 at episode 170\n",
            "running reward: 191.89 at episode 180\n",
            "running reward: 168.67 at episode 190\n",
            "running reward: 175.14 at episode 200\n",
            "running reward: 185.11 at episode 210\n",
            "running reward: 191.09 at episode 220\n",
            "running reward: 194.66 at episode 230\n",
            "Solved at episode 232!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_1ZB2nKFiAg",
        "colab_type": "code",
        "outputId": "86d66ccc-1ea8-4f24-da80-f68f83467c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# test della rete addestrata\n",
        "\n",
        "state = env.reset()\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "done = False\n",
        "i = 0\n",
        "while not done:\n",
        "    state = tf.convert_to_tensor(state)\n",
        "    state = tf.expand_dims(state, 0)\n",
        "    action_probs, critic_value = model(state)\n",
        "    action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n",
        "    img.set_data(env.render(mode='rgb_array')) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    state, reward, done, _ = env.step(action) \n",
        "    i = i + 1   \n",
        "env.close()\n",
        "print('run for: %i steps' %(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run for: 200 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICbpRYQAdL5q",
        "colab_type": "text"
      },
      "source": [
        "# Deep Q Networks\n",
        "\n",
        "I DQN introdotte da Google nel 2013 fanno parte della classe di metodi di RL cosidetti di *value function based policies*. In questo tipo di metodi l'azione viene appresa rispetto ad un dato stato in base ad un cosidetto Q-value: un reward pesato basato su il massimo reward atteso nel futuro. Il task rispetto a cui viene addestrato il Q-agent è quella di raccomandare azioni che massimizzano il reward potenziale futuro. \n",
        "Nei DQN la Q-function è approssimata con un DNN.\n",
        "\n",
        "Elementi:\n",
        "\n",
        "$Q(s,a)$: Q-function, funzione dello stato *s* e azione *a*, approssimata in una DQN da una rete neurale profonda.\n",
        "\n",
        "Loss: $L = \\frac{1}{2}(r + \\gamma \\underset{{a'}}\\max \\hat{Q}(s,a') - Q(s,a) )^2$\n",
        "\n",
        "in cui:\n",
        "\n",
        "*   i primi due termini rappresentano il target\n",
        "*   il secondo termine la predizione\n",
        "*   $\\gamma$ è il discount factor\n",
        "\n",
        "L'agente esegue l'azione *a* e osserva un reward *r* e un nuovo stato *s'*. Sulla base di questo calcola il massimo target Q e lo sconta in modo che i reward futuri abbiano sempre meno peso rispetto ai reward immediati (in modo simile al rate di interesse su un prestito). A questo punto il reward corrente viene sommato al reward futuro scontato per costruire il target che viene confrontato con la predizione corrente tramite una MSE-like.\n",
        "\n",
        "Due caratteristiche fondamentali dell'algoritmo DQN sono i concetti di *memory* e *replay*:\n",
        "\n",
        "*   *memory*: uno dei problemi principali per una DQN è legato al fatto che la DNN usata dall'algoritmo tende a dimenticare velocemente l'esperienza pregressa mano a mano che sovrascrive (aggiorna i pesi) con nuova esperienza. Per risolvere il problema viene mantenuta una lista delle esperienze e osservazioni precedenti che viene utilizzata per ri-addestrare il modello con tutta l'esperienza passata. Questa lista viene chiamata memory e memorizza in una lista lo stato, l'azione, il reward e lo stato successivo ad ogni step del processo analizzato.\n",
        "*   *replay*: è la parte del NN che addestra la rete con lesperienza salvata in memory.  In pratica campiona un batch di esperienze da memory (minibatch), e per tali azioni stima il discounted future reward.\n",
        "\n",
        "L'azione raccomandata dall'agente iniziamente è per una certa percentuale (detta epsilon o exploration rate) di tipo random. Questo garantisce inzialmente all'agente la possibilità di esplorare tutte le possibilità di azione prima di essere in grado di riconoscerene i pattern. Mano a mano che il training avanza il rate di esplorazione random viene ridotto, e l'agente sostanzialmente predice il reward basansosi sullo stato corrente e raccomanda l'azione che produce il massimo reward. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w08hMvzxx4oi",
        "colab_type": "text"
      },
      "source": [
        "### MountainCar-v0: con policy random o policy elementare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9fVQ1OZz2lT",
        "colab_type": "code",
        "outputId": "d70b9cce-6b46-4de9-95e7-5440db13a02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed = 12345\n",
        "\n",
        "env = gym.make(\"MountainCar-v0\")  # Create the environment\n",
        "env.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12345]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sA9WWhY7JlK",
        "colab_type": "code",
        "outputId": "098d421a-9bc0-4446-d0c6-f8e515854faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Simple Policy (i.e. agire nella direzione del moto)\n",
        "def simple_policy(obs, i):\n",
        "    vel = obs[1]\n",
        "    pos = obs[0]+0.5 #minimum in 0\n",
        "# al primo step (v=0) accelera in direzione della discesa   \n",
        "    if i == 0:\n",
        "        return 0 if pos > 0 else 2\n",
        " # ai successivi accelera nella direzione in cui ci si sta muovendo     \n",
        "    return 2 if vel > 0 else 0\n",
        "\n",
        "\n",
        "# seleziona simple or random policy\n",
        "random_policy = False\n",
        "\n",
        "state = env.reset()\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "done = False\n",
        "i = 0\n",
        "while not done:\n",
        "    if random_policy:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = simple_policy(state, i)\n",
        "    img.set_data(env.render(mode='rgb_array')) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    state, reward, done, _ = env.step(action) \n",
        "    i = i + 1   \n",
        "env.close()\n",
        "print('run for: %i steps' %(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run for: 171 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMM3SxZPSNw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DQN algorithm\n",
        "# Dueling-DQN (DDQN) Implementation (più stabile rispetto a plain DQN)\n",
        "# https://arxiv.org/pdf/1511.06581.pdf\n",
        "\n",
        "# ci sono due reti neurali separate invece che una sola che fa entrambe le cose:\n",
        "# il Q-network che seleziona l'azione, e il target Q-network che valuta l'azione\n",
        "\n",
        "class DQN:\n",
        "    def __init__(self, env):\n",
        "        self.env=env\n",
        "        self.gamma=0.99 #discount rate\n",
        "        self.epsilon = 1\n",
        "        self.epsilon_decay = 0.05\n",
        "        self.epsilon_min=0.01\n",
        "        self.episodes=300 #numero di episodi\n",
        "        self.iterations=201 #200 è il limite imposto dall'environment\n",
        "        self.batch_size=32 #batch size quando si campiona memory\n",
        "        self.memory=deque(maxlen=20000)\n",
        "        \n",
        "        self.model_train=self.model()\n",
        "        self.model_target=self.model()\n",
        "        self.model_target.set_weights(self.model_train.get_weights())\n",
        "\n",
        "    def model(self): #modello rete neurale\n",
        "        state_shape = self.env.observation_space.shape\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(layers.Dense(24, activation='relu', input_shape=state_shape))\n",
        "        model.add(layers.Dense(48, activation='relu'))\n",
        "        model.add(layers.Dense(self.env.action_space.n,activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))\n",
        "        return model\n",
        "\n",
        "    def act(self,state): #calcola l'azione\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
        "\n",
        "        if np.random.rand(1) < self.epsilon: #parte random\n",
        "            action = np.random.randint(0, 3)\n",
        "        else: #parte non random\n",
        "            action = np.argmax(self.model_train.predict(state)[0])\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "    def replay(self): #replay \n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        samples = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        states = []\n",
        "        newStates=[]\n",
        "        for sample in samples:\n",
        "            state, action, reward, new_state, done = sample\n",
        "            states.append(state)\n",
        "            newStates.append(new_state)\n",
        "\n",
        "        newArray = np.array(states)\n",
        "        states = newArray.reshape(self.batch_size, 2)\n",
        "\n",
        "        newArray2 = np.array(newStates)\n",
        "        newStates = newArray2.reshape(self.batch_size, 2)\n",
        "\n",
        "        targets = self.model_train.predict(states)\n",
        "        new_state_targets=self.model_target.predict(newStates)\n",
        "\n",
        "        i=0\n",
        "        for sample in samples:\n",
        "            state, action, reward, new_state, done = sample\n",
        "            target = targets[i]\n",
        "            if done:\n",
        "                target[action] = reward\n",
        "            else:\n",
        "                Q_future = max(new_state_targets[i])\n",
        "                target[action] = reward + Q_future * self.gamma\n",
        "            i+=1\n",
        "\n",
        "        self.model_train.fit(states, targets, epochs=1, verbose=0)\n",
        "\n",
        "\n",
        "    def train(self, currentState, eps): #training\n",
        "        rewardSum = 0\n",
        "        max_position=-99\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "            bestAction = self.act(currentState)\n",
        "\n",
        "            new_state, reward, done, _ = env.step(bestAction)\n",
        "\n",
        "            new_state = new_state.reshape(1, 2)\n",
        "\n",
        "            # Tiene traccia della massima posizione della macchina (il goal è arrivare a 0.5)\n",
        "            if new_state[0][0] > max_position:\n",
        "                max_position = new_state[0][0]\n",
        "\n",
        "            # Nel caso di succeso big boost al reward (10 invece che zero)\n",
        "            if new_state[0][0] >= 0.5:\n",
        "                reward += 10\n",
        "\n",
        "            # Modifica del reward per tenere conto che fino a quando la macchina non raggiung 0.5 \n",
        "            # non riceve nessun reward (reward è -1 per ogni step e +10 quando arriva in cima)\n",
        "            # diamo un reward proporzionale a quanto è risucita a salire in alto la macchina\n",
        "            # NB altezza della macchina = np.sin(3 * posizione)*.45+.55\n",
        "\n",
        "            if new_state[0][0] >= -0.4:\n",
        "               reward += (np.sin(3 * new_state[0][0])*.45+.55+0.45)**2\n",
        "\n",
        "            # Memorize\n",
        "            self.memory.append([currentState, bestAction, reward, new_state, done])\n",
        "\n",
        "            # Replay\n",
        "            self.replay()\n",
        "\n",
        "            rewardSum += reward\n",
        "\n",
        "            currentState = new_state\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if i >= 199:\n",
        "            print(\"Failed to finish task in epsoide {}\".format(eps))\n",
        "        else:\n",
        "            print(\"Success in epsoide {}, used {} iterations!\".format(eps, i))\n",
        "            self.model_train.save('./bestDQNnet.h5')\n",
        "\n",
        "        #Sync\n",
        "        self.model_target.set_weights(self.model_train.get_weights())\n",
        "\n",
        "        print(\"now epsilon is {}, the reward is {} maxPosition is {}\".format(max(self.epsilon_min, self.epsilon), rewardSum,max_position))\n",
        "        self.epsilon -= self.epsilon_decay\n",
        "\n",
        "    def start(self):\n",
        "        for eps in range(self.episodes):\n",
        "            currentState=env.reset().reshape(1,2)\n",
        "            self.train(currentState, eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6sTDiSExYY",
        "colab_type": "code",
        "outputId": "aeb26a58-0653-47fc-d009-a1fa442f0dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "dqn=DQN(env=env)\n",
        "dqn.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to finish task in epsoide 0\n",
            "now epsilon is 1, the reward is -200.0 maxPosition is -0.43977217571148175\n",
            "Failed to finish task in epsoide 1\n",
            "now epsilon is 0.95, the reward is -195.49894453410403 maxPosition is -0.377860606193882\n",
            "Failed to finish task in epsoide 2\n",
            "now epsilon is 0.8999999999999999, the reward is -200.0 maxPosition is -0.4000804064020402\n",
            "Failed to finish task in epsoide 3\n",
            "now epsilon is 0.8499999999999999, the reward is -185.42807652056428 maxPosition is -0.32309004475544645\n",
            "Failed to finish task in epsoide 4\n",
            "now epsilon is 0.7999999999999998, the reward is -200.0 maxPosition is -0.41793618647659847\n",
            "Failed to finish task in epsoide 5\n",
            "now epsilon is 0.7499999999999998, the reward is -194.20387529893944 maxPosition is -0.3459367974376714\n",
            "Failed to finish task in epsoide 6\n",
            "now epsilon is 0.6999999999999997, the reward is -195.0400248300165 maxPosition is -0.3620523877690259\n",
            "Failed to finish task in epsoide 7\n",
            "now epsilon is 0.6499999999999997, the reward is -186.5605040110623 maxPosition is -0.328023444739466\n",
            "Failed to finish task in epsoide 8\n",
            "now epsilon is 0.5999999999999996, the reward is -192.8359489559918 maxPosition is -0.34841680007621306\n",
            "Failed to finish task in epsoide 9\n",
            "now epsilon is 0.5499999999999996, the reward is -200.0 maxPosition is -0.42396942354690925\n",
            "Failed to finish task in epsoide 10\n",
            "now epsilon is 0.4999999999999996, the reward is -195.2583504802642 maxPosition is -0.3952255053035966\n",
            "Failed to finish task in epsoide 11\n",
            "now epsilon is 0.4499999999999996, the reward is -188.07918454267553 maxPosition is -0.32911535111746754\n",
            "Failed to finish task in epsoide 12\n",
            "now epsilon is 0.39999999999999963, the reward is -181.12213512835646 maxPosition is -0.2149125493945652\n",
            "Failed to finish task in epsoide 13\n",
            "now epsilon is 0.34999999999999964, the reward is -192.10877790624806 maxPosition is -0.32148194236344996\n",
            "Failed to finish task in epsoide 14\n",
            "now epsilon is 0.29999999999999966, the reward is -200.0 maxPosition is -0.41458887020960333\n",
            "Failed to finish task in epsoide 15\n",
            "now epsilon is 0.24999999999999967, the reward is -200.0 maxPosition is -0.4009437940663433\n",
            "Failed to finish task in epsoide 16\n",
            "now epsilon is 0.19999999999999968, the reward is -175.06327487506778 maxPosition is -0.16219471938361144\n",
            "Failed to finish task in epsoide 17\n",
            "now epsilon is 0.1499999999999997, the reward is -169.10493679334343 maxPosition is -0.16972492702336875\n",
            "Failed to finish task in epsoide 18\n",
            "now epsilon is 0.09999999999999969, the reward is -157.9710829098871 maxPosition is 0.03329433165713717\n",
            "Failed to finish task in epsoide 19\n",
            "now epsilon is 0.049999999999999684, the reward is -137.73670916716503 maxPosition is 0.11582578385779613\n",
            "Failed to finish task in epsoide 20\n",
            "now epsilon is 0.01, the reward is -134.43680686955116 maxPosition is 0.11683502782693177\n",
            "Failed to finish task in epsoide 21\n",
            "now epsilon is 0.01, the reward is -151.49281224308066 maxPosition is -0.03904605080752978\n",
            "Failed to finish task in epsoide 22\n",
            "now epsilon is 0.01, the reward is -157.19344856909635 maxPosition is -0.13394191633993902\n",
            "Failed to finish task in epsoide 23\n",
            "now epsilon is 0.01, the reward is -185.51961405219242 maxPosition is -0.25354730411610654\n",
            "Failed to finish task in epsoide 24\n",
            "now epsilon is 0.01, the reward is -184.87158080752926 maxPosition is -0.2850724164344309\n",
            "Failed to finish task in epsoide 25\n",
            "now epsilon is 0.01, the reward is -133.17137217418855 maxPosition is 0.3058702785925703\n",
            "Failed to finish task in epsoide 26\n",
            "now epsilon is 0.01, the reward is -135.1829431206661 maxPosition is 0.0795428500829431\n",
            "Failed to finish task in epsoide 27\n",
            "now epsilon is 0.01, the reward is -140.9689748461376 maxPosition is 0.06458083369772878\n",
            "Failed to finish task in epsoide 28\n",
            "now epsilon is 0.01, the reward is -134.7042901961896 maxPosition is 0.11155227459376163\n",
            "Failed to finish task in epsoide 29\n",
            "now epsilon is 0.01, the reward is -104.35194867288489 maxPosition is 0.2449694298987061\n",
            "Failed to finish task in epsoide 30\n",
            "now epsilon is 0.01, the reward is -161.56342002271344 maxPosition is -0.20285019094111215\n",
            "Failed to finish task in epsoide 31\n",
            "now epsilon is 0.01, the reward is -144.19891385967264 maxPosition is -0.13972810968180438\n",
            "Failed to finish task in epsoide 32\n",
            "now epsilon is 0.01, the reward is -158.28110323055276 maxPosition is -0.1339805222281149\n",
            "Failed to finish task in epsoide 33\n",
            "now epsilon is 0.01, the reward is -138.27262374888244 maxPosition is 0.07782207644619801\n",
            "Failed to finish task in epsoide 34\n",
            "now epsilon is 0.01, the reward is -139.91961700726247 maxPosition is 0.06977339204899602\n",
            "Failed to finish task in epsoide 35\n",
            "now epsilon is 0.01, the reward is -145.5430669298669 maxPosition is -0.03335714130219946\n",
            "Failed to finish task in epsoide 36\n",
            "now epsilon is 0.01, the reward is -158.17280345021885 maxPosition is -0.12299919231509683\n",
            "Failed to finish task in epsoide 37\n",
            "now epsilon is 0.01, the reward is -132.8439450534503 maxPosition is 0.10630666620178705\n",
            "Failed to finish task in epsoide 38\n",
            "now epsilon is 0.01, the reward is -161.71262052861042 maxPosition is -0.2165776726688514\n",
            "Failed to finish task in epsoide 39\n",
            "now epsilon is 0.01, the reward is -157.6066140522664 maxPosition is -0.198731008862017\n",
            "Failed to finish task in epsoide 40\n",
            "now epsilon is 0.01, the reward is -153.21146489796342 maxPosition is -0.12378491482246727\n",
            "Failed to finish task in epsoide 41\n",
            "now epsilon is 0.01, the reward is -135.71116420103596 maxPosition is 0.12323907248223266\n",
            "Failed to finish task in epsoide 42\n",
            "now epsilon is 0.01, the reward is -155.1805715576916 maxPosition is -0.338993578409294\n",
            "Failed to finish task in epsoide 43\n",
            "now epsilon is 0.01, the reward is -131.7095789672432 maxPosition is -0.008789794810981464\n",
            "Failed to finish task in epsoide 44\n",
            "now epsilon is 0.01, the reward is -145.86891103556846 maxPosition is -0.18106560160516966\n",
            "Failed to finish task in epsoide 45\n",
            "now epsilon is 0.01, the reward is -157.9469987751043 maxPosition is -0.1506219161382602\n",
            "Failed to finish task in epsoide 46\n",
            "now epsilon is 0.01, the reward is -130.32036252285417 maxPosition is 0.13662323339003252\n",
            "Success in epsoide 47, used 135 iterations!\n",
            "now epsilon is 0.01, the reward is -43.13312567139458 maxPosition is 0.5081488797707855\n",
            "Failed to finish task in epsoide 48\n",
            "now epsilon is 0.01, the reward is -85.77104847735363 maxPosition is 0.28761880905757303\n",
            "Failed to finish task in epsoide 49\n",
            "now epsilon is 0.01, the reward is -110.85421091698117 maxPosition is 0.23110826049052674\n",
            "Failed to finish task in epsoide 50\n",
            "now epsilon is 0.01, the reward is -153.90372568303013 maxPosition is -0.2857218822827013\n",
            "Failed to finish task in epsoide 51\n",
            "now epsilon is 0.01, the reward is -153.18114107076636 maxPosition is -0.16902980845555882\n",
            "Failed to finish task in epsoide 52\n",
            "now epsilon is 0.01, the reward is -143.718336733588 maxPosition is -0.15015782817285786\n",
            "Failed to finish task in epsoide 53\n",
            "now epsilon is 0.01, the reward is -161.05438187329537 maxPosition is -0.23448852763515063\n",
            "Failed to finish task in epsoide 54\n",
            "now epsilon is 0.01, the reward is -159.06615927390828 maxPosition is -0.13492291481640012\n",
            "Failed to finish task in epsoide 55\n",
            "now epsilon is 0.01, the reward is -152.52938228099623 maxPosition is -0.2525979972329943\n",
            "Failed to finish task in epsoide 56\n",
            "now epsilon is 0.01, the reward is -127.53366186393372 maxPosition is 0.030066099733255962\n",
            "Failed to finish task in epsoide 57\n",
            "now epsilon is 0.01, the reward is -151.75685018443139 maxPosition is -0.252331670139279\n",
            "Failed to finish task in epsoide 58\n",
            "now epsilon is 0.01, the reward is -137.97091825468516 maxPosition is 0.012439380036693513\n",
            "Failed to finish task in epsoide 59\n",
            "now epsilon is 0.01, the reward is -164.58663834605517 maxPosition is -0.2512402855084975\n",
            "Failed to finish task in epsoide 60\n",
            "now epsilon is 0.01, the reward is -139.2900398269062 maxPosition is -0.10229347950815981\n",
            "Failed to finish task in epsoide 61\n",
            "now epsilon is 0.01, the reward is -130.02105627144394 maxPosition is 0.18746628001076712\n",
            "Failed to finish task in epsoide 62\n",
            "now epsilon is 0.01, the reward is -144.30255273798116 maxPosition is 0.06247167451807305\n",
            "Failed to finish task in epsoide 63\n",
            "now epsilon is 0.01, the reward is -152.4065213761721 maxPosition is -0.24316971061806872\n",
            "Failed to finish task in epsoide 64\n",
            "now epsilon is 0.01, the reward is -131.69380986932805 maxPosition is 0.4606402916214511\n",
            "Failed to finish task in epsoide 65\n",
            "now epsilon is 0.01, the reward is -173.12510418739822 maxPosition is -0.2190632276947939\n",
            "Success in epsoide 66, used 120 iterations!\n",
            "now epsilon is 0.01, the reward is -55.322806712512154 maxPosition is 0.517970580582402\n",
            "Failed to finish task in epsoide 67\n",
            "now epsilon is 0.01, the reward is -115.7695279697002 maxPosition is 0.22031828993441435\n",
            "Failed to finish task in epsoide 68\n",
            "now epsilon is 0.01, the reward is -113.7599112481342 maxPosition is 0.2380976764938485\n",
            "Failed to finish task in epsoide 69\n",
            "now epsilon is 0.01, the reward is -169.91133422202248 maxPosition is -0.21657507366145917\n",
            "Failed to finish task in epsoide 70\n",
            "now epsilon is 0.01, the reward is -151.00267787365314 maxPosition is -0.1140471490353535\n",
            "Failed to finish task in epsoide 71\n",
            "now epsilon is 0.01, the reward is -157.81503797118978 maxPosition is -0.19191319275385568\n",
            "Failed to finish task in epsoide 72\n",
            "now epsilon is 0.01, the reward is -147.7966370845267 maxPosition is 0.03547416568231419\n",
            "Failed to finish task in epsoide 73\n",
            "now epsilon is 0.01, the reward is -131.11189680728137 maxPosition is 0.05099727740769358\n",
            "Failed to finish task in epsoide 74\n",
            "now epsilon is 0.01, the reward is -135.49216636049022 maxPosition is 0.346381104672638\n",
            "Failed to finish task in epsoide 75\n",
            "now epsilon is 0.01, the reward is -125.04848649695018 maxPosition is 0.06519672023730742\n",
            "Failed to finish task in epsoide 76\n",
            "now epsilon is 0.01, the reward is -169.7302253695844 maxPosition is -0.051850005611537096\n",
            "Failed to finish task in epsoide 77\n",
            "now epsilon is 0.01, the reward is -156.66568034138362 maxPosition is -0.2148325077805881\n",
            "Failed to finish task in epsoide 78\n",
            "now epsilon is 0.01, the reward is -176.52723098233815 maxPosition is -0.10209365074461174\n",
            "Failed to finish task in epsoide 79\n",
            "now epsilon is 0.01, the reward is -159.3399615834507 maxPosition is -0.10618648043290116\n",
            "Failed to finish task in epsoide 80\n",
            "now epsilon is 0.01, the reward is -161.67218480908468 maxPosition is -0.11409071390307568\n",
            "Failed to finish task in epsoide 81\n",
            "now epsilon is 0.01, the reward is -147.9217035048483 maxPosition is -0.031600242097360384\n",
            "Failed to finish task in epsoide 82\n",
            "now epsilon is 0.01, the reward is -178.3680320309294 maxPosition is -0.25317620359135184\n",
            "Failed to finish task in epsoide 83\n",
            "now epsilon is 0.01, the reward is -145.55384375361288 maxPosition is -0.02023446146598038\n",
            "Failed to finish task in epsoide 84\n",
            "now epsilon is 0.01, the reward is -171.99693030070668 maxPosition is -0.14557736354990367\n",
            "Failed to finish task in epsoide 85\n",
            "now epsilon is 0.01, the reward is -183.27350695236456 maxPosition is -0.28633911769605613\n",
            "Failed to finish task in epsoide 86\n",
            "now epsilon is 0.01, the reward is -115.6729293966848 maxPosition is 0.24448078894969785\n",
            "Failed to finish task in epsoide 87\n",
            "now epsilon is 0.01, the reward is -156.32969636516137 maxPosition is 0.20369615633746202\n",
            "Failed to finish task in epsoide 88\n",
            "now epsilon is 0.01, the reward is -191.54112824099502 maxPosition is -0.07128780049601222\n",
            "Failed to finish task in epsoide 89\n",
            "now epsilon is 0.01, the reward is -163.511341760157 maxPosition is -0.14232790862838474\n",
            "Failed to finish task in epsoide 90\n",
            "now epsilon is 0.01, the reward is -148.39341589956837 maxPosition is -0.06920173749676721\n",
            "Failed to finish task in epsoide 91\n",
            "now epsilon is 0.01, the reward is -153.4464729344279 maxPosition is -0.06510777956825291\n",
            "Success in epsoide 92, used 195 iterations!\n",
            "now epsilon is 0.01, the reward is -106.8003584900626 maxPosition is 0.5018844760471443\n",
            "Failed to finish task in epsoide 93\n",
            "now epsilon is 0.01, the reward is -141.3215882914376 maxPosition is 0.10803729352237455\n",
            "Failed to finish task in epsoide 94\n",
            "now epsilon is 0.01, the reward is -113.1639507679511 maxPosition is 0.2114611791827733\n",
            "Failed to finish task in epsoide 95\n",
            "now epsilon is 0.01, the reward is -162.2023955763047 maxPosition is -0.14293402875127012\n",
            "Failed to finish task in epsoide 96\n",
            "now epsilon is 0.01, the reward is -144.76204991525825 maxPosition is 0.10347308251152268\n",
            "Failed to finish task in epsoide 97\n",
            "now epsilon is 0.01, the reward is -149.25905597606723 maxPosition is 0.02697591420644848\n",
            "Failed to finish task in epsoide 98\n",
            "now epsilon is 0.01, the reward is -51.263040671984456 maxPosition is 0.3387814810614029\n",
            "Failed to finish task in epsoide 99\n",
            "now epsilon is 0.01, the reward is -127.15234784911483 maxPosition is 0.4028500673719039\n",
            "Failed to finish task in epsoide 100\n",
            "now epsilon is 0.01, the reward is -174.39232458560963 maxPosition is -0.22819710464871146\n",
            "Failed to finish task in epsoide 101\n",
            "now epsilon is 0.01, the reward is -152.642311451588 maxPosition is 0.03694852765752664\n",
            "Success in epsoide 102, used 135 iterations!\n",
            "now epsilon is 0.01, the reward is -47.24779850584048 maxPosition is 0.5037673503025074\n",
            "Success in epsoide 103, used 173 iterations!\n",
            "now epsilon is 0.01, the reward is -67.05945541368807 maxPosition is 0.5087584616479012\n",
            "Failed to finish task in epsoide 104\n",
            "now epsilon is 0.01, the reward is -154.73250390478267 maxPosition is -0.16677465889921145\n",
            "Failed to finish task in epsoide 105\n",
            "now epsilon is 0.01, the reward is -161.04901017974777 maxPosition is -0.003052883086102697\n",
            "Failed to finish task in epsoide 106\n",
            "now epsilon is 0.01, the reward is -30.733649048881407 maxPosition is 0.3549386285870654\n",
            "Failed to finish task in epsoide 107\n",
            "now epsilon is 0.01, the reward is -181.44705579560684 maxPosition is -0.2243870922827766\n",
            "Success in epsoide 108, used 193 iterations!\n",
            "now epsilon is 0.01, the reward is -117.0805879921876 maxPosition is 0.5019919885599875\n",
            "Failed to finish task in epsoide 109\n",
            "now epsilon is 0.01, the reward is -121.81825249021583 maxPosition is 0.18229142754388428\n",
            "Failed to finish task in epsoide 110\n",
            "now epsilon is 0.01, the reward is -165.72305811694713 maxPosition is -0.18807486109619914\n",
            "Failed to finish task in epsoide 111\n",
            "now epsilon is 0.01, the reward is -155.23884229969835 maxPosition is -0.026328404091311854\n",
            "Success in epsoide 112, used 194 iterations!\n",
            "now epsilon is 0.01, the reward is -103.25288372564751 maxPosition is 0.5156486644470746\n",
            "Success in epsoide 113, used 118 iterations!\n",
            "now epsilon is 0.01, the reward is -61.83623196316601 maxPosition is 0.5257261619249798\n",
            "Failed to finish task in epsoide 114\n",
            "now epsilon is 0.01, the reward is -117.10299864399106 maxPosition is 0.19375430302305865\n",
            "Success in epsoide 115, used 126 iterations!\n",
            "now epsilon is 0.01, the reward is -39.8189105681449 maxPosition is 0.5033898679876572\n",
            "Success in epsoide 116, used 170 iterations!\n",
            "now epsilon is 0.01, the reward is -81.85199918500363 maxPosition is 0.5147808157362165\n",
            "Failed to finish task in epsoide 117\n",
            "now epsilon is 0.01, the reward is -179.08518000733903 maxPosition is -0.17458700292132645\n",
            "Failed to finish task in epsoide 118\n",
            "now epsilon is 0.01, the reward is -190.0777210547585 maxPosition is -0.3039136419742284\n",
            "Failed to finish task in epsoide 119\n",
            "now epsilon is 0.01, the reward is -153.37372469601434 maxPosition is 0.2942258201051101\n",
            "Success in epsoide 120, used 164 iterations!\n",
            "now epsilon is 0.01, the reward is -85.22003775949658 maxPosition is 0.5114253476192407\n",
            "Success in epsoide 121, used 135 iterations!\n",
            "now epsilon is 0.01, the reward is -76.28965917951349 maxPosition is 0.5219142638576559\n",
            "Failed to finish task in epsoide 122\n",
            "now epsilon is 0.01, the reward is -180.48868847498937 maxPosition is -0.06272290313283992\n",
            "Failed to finish task in epsoide 123\n",
            "now epsilon is 0.01, the reward is -163.6931800489466 maxPosition is 0.18475133427589602\n",
            "Failed to finish task in epsoide 124\n",
            "now epsilon is 0.01, the reward is -184.82404264929906 maxPosition is -0.1482762052611562\n",
            "Success in epsoide 125, used 184 iterations!\n",
            "now epsilon is 0.01, the reward is -65.44515429494898 maxPosition is 0.5002276327194155\n",
            "Failed to finish task in epsoide 126\n",
            "now epsilon is 0.01, the reward is -141.7406274854277 maxPosition is 0.3020251086258556\n",
            "Success in epsoide 127, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -89.73865512174949 maxPosition is 0.5336462199286459\n",
            "Success in epsoide 128, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -71.76606733737164 maxPosition is 0.5018827870921408\n",
            "Success in epsoide 129, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -79.67583155343058 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 130, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -81.999632949994 maxPosition is 0.5019744065101399\n",
            "Failed to finish task in epsoide 131\n",
            "now epsilon is 0.01, the reward is -126.15933910757239 maxPosition is 0.22645563972784466\n",
            "Failed to finish task in epsoide 132\n",
            "now epsilon is 0.01, the reward is -194.7516449095536 maxPosition is -0.36798883848998964\n",
            "Success in epsoide 133, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -82.63213687666624 maxPosition is 0.5267486208648002\n",
            "Success in epsoide 134, used 98 iterations!\n",
            "now epsilon is 0.01, the reward is -21.530292913149204 maxPosition is 0.5114333508660246\n",
            "Failed to finish task in epsoide 135\n",
            "now epsilon is 0.01, the reward is -186.6190295560187 maxPosition is 0.1508524202288153\n",
            "Failed to finish task in epsoide 136\n",
            "now epsilon is 0.01, the reward is -110.098213769215 maxPosition is 0.311154446195993\n",
            "Failed to finish task in epsoide 137\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5424994049810047\n",
            "Failed to finish task in epsoide 138\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5914498444456732\n",
            "Failed to finish task in epsoide 139\n",
            "now epsilon is 0.01, the reward is -189.40989840867337 maxPosition is -0.26943578530800105\n",
            "Success in epsoide 140, used 178 iterations!\n",
            "now epsilon is 0.01, the reward is -121.13998568340602 maxPosition is 0.5008757097163388\n",
            "Success in epsoide 141, used 180 iterations!\n",
            "now epsilon is 0.01, the reward is -105.8834358573188 maxPosition is 0.5438067952167948\n",
            "Success in epsoide 142, used 104 iterations!\n",
            "now epsilon is 0.01, the reward is -40.25020597820606 maxPosition is 0.5050566325121371\n",
            "Success in epsoide 143, used 111 iterations!\n",
            "now epsilon is 0.01, the reward is -25.433253933790752 maxPosition is 0.5112353017490486\n",
            "Failed to finish task in epsoide 144\n",
            "now epsilon is 0.01, the reward is -167.16377132052733 maxPosition is 0.022841697228054375\n",
            "Failed to finish task in epsoide 145\n",
            "now epsilon is 0.01, the reward is -145.52702563370812 maxPosition is 0.15507764075708141\n",
            "Failed to finish task in epsoide 146\n",
            "now epsilon is 0.01, the reward is -158.98255298273077 maxPosition is 0.058034672061076244\n",
            "Success in epsoide 147, used 123 iterations!\n",
            "now epsilon is 0.01, the reward is -74.24594075978028 maxPosition is 0.5256186524539419\n",
            "Failed to finish task in epsoide 148\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4641199814312428\n",
            "Success in epsoide 149, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -100.80296310072711 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 150, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -84.65386552503398 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 151, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -91.79344073895123 maxPosition is 0.5308208934604665\n",
            "Failed to finish task in epsoide 152\n",
            "now epsilon is 0.01, the reward is -151.28520935465323 maxPosition is 0.24348822247771224\n",
            "Success in epsoide 153, used 175 iterations!\n",
            "now epsilon is 0.01, the reward is -82.80370031598639 maxPosition is 0.5267486208648002\n",
            "Success in epsoide 154, used 94 iterations!\n",
            "now epsilon is 0.01, the reward is -32.770020765922276 maxPosition is 0.500296200490634\n",
            "Success in epsoide 155, used 170 iterations!\n",
            "now epsilon is 0.01, the reward is -86.49455691967617 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 156, used 158 iterations!\n",
            "now epsilon is 0.01, the reward is -85.35406665703086 maxPosition is 0.5306184377787105\n",
            "Success in epsoide 157, used 94 iterations!\n",
            "now epsilon is 0.01, the reward is -26.91802730919639 maxPosition is 0.5048799393519623\n",
            "Success in epsoide 158, used 102 iterations!\n",
            "now epsilon is 0.01, the reward is -37.51127365351037 maxPosition is 0.5082062814177415\n",
            "Success in epsoide 159, used 100 iterations!\n",
            "now epsilon is 0.01, the reward is -31.74471613911578 maxPosition is 0.5080384297593413\n",
            "Success in epsoide 160, used 110 iterations!\n",
            "now epsilon is 0.01, the reward is -62.93776312388243 maxPosition is 0.5153691504718927\n",
            "Success in epsoide 161, used 176 iterations!\n",
            "now epsilon is 0.01, the reward is -118.54722245337993 maxPosition is 0.5153691504718927\n",
            "Success in epsoide 162, used 170 iterations!\n",
            "now epsilon is 0.01, the reward is -84.29926210541056 maxPosition is 0.5406700342215449\n",
            "Success in epsoide 163, used 127 iterations!\n",
            "now epsilon is 0.01, the reward is -74.13170826909024 maxPosition is 0.5157791652314404\n",
            "Success in epsoide 164, used 129 iterations!\n",
            "now epsilon is 0.01, the reward is -79.95946195350469 maxPosition is 0.5151972789687942\n",
            "Success in epsoide 165, used 133 iterations!\n",
            "now epsilon is 0.01, the reward is -75.44508521516249 maxPosition is 0.5043590578948594\n",
            "Success in epsoide 166, used 183 iterations!\n",
            "now epsilon is 0.01, the reward is -92.5244141242216 maxPosition is 0.5114990196244081\n",
            "Success in epsoide 167, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is 48.892536412375755 maxPosition is 0.500971522041861\n",
            "Failed to finish task in epsoide 168\n",
            "now epsilon is 0.01, the reward is 8.526196300352899 maxPosition is 0.48859850534994\n",
            "Failed to finish task in epsoide 169\n",
            "now epsilon is 0.01, the reward is 73.65517944056955 maxPosition is 0.4221603049450141\n",
            "Failed to finish task in epsoide 170\n",
            "now epsilon is 0.01, the reward is 29.12063969062836 maxPosition is 0.4048005786279729\n",
            "Failed to finish task in epsoide 171\n",
            "now epsilon is 0.01, the reward is -20.686106857472616 maxPosition is 0.4026310790786215\n",
            "Failed to finish task in epsoide 172\n",
            "now epsilon is 0.01, the reward is -19.97344635186314 maxPosition is 0.3867984593088682\n",
            "Success in epsoide 173, used 162 iterations!\n",
            "now epsilon is 0.01, the reward is -73.32893856978883 maxPosition is 0.5122319221063341\n",
            "Failed to finish task in epsoide 174\n",
            "now epsilon is 0.01, the reward is 67.72095816846922 maxPosition is 0.43626595812266455\n",
            "Success in epsoide 175, used 179 iterations!\n",
            "now epsilon is 0.01, the reward is -112.39784650701861 maxPosition is 0.5039592505116969\n",
            "Failed to finish task in epsoide 176\n",
            "now epsilon is 0.01, the reward is -20.38718355743664 maxPosition is 0.37545653182032585\n",
            "Failed to finish task in epsoide 177\n",
            "now epsilon is 0.01, the reward is -79.99890146133654 maxPosition is 0.37050981579748055\n",
            "Failed to finish task in epsoide 178\n",
            "now epsilon is 0.01, the reward is -76.07292802339182 maxPosition is 0.3493597150780014\n",
            "Success in epsoide 179, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -61.84278816788124 maxPosition is 0.5055663526090013\n",
            "Success in epsoide 180, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -81.85329906370409 maxPosition is 0.5113273087420274\n",
            "Failed to finish task in epsoide 181\n",
            "now epsilon is 0.01, the reward is -91.05008550718439 maxPosition is 0.4300231364784054\n",
            "Success in epsoide 182, used 175 iterations!\n",
            "now epsilon is 0.01, the reward is -39.65579890849997 maxPosition is 0.5093086887731507\n",
            "Success in epsoide 183, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -63.23295174095088 maxPosition is 0.5301156339088621\n",
            "Success in epsoide 184, used 109 iterations!\n",
            "now epsilon is 0.01, the reward is -58.75847542267726 maxPosition is 0.5108013689363462\n",
            "Success in epsoide 185, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -65.5949794509313 maxPosition is 0.5063586906822063\n",
            "Success in epsoide 186, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -63.62065237338501 maxPosition is 0.5301156339088621\n",
            "Success in epsoide 187, used 109 iterations!\n",
            "now epsilon is 0.01, the reward is -56.93643149770846 maxPosition is 0.5008950690517926\n",
            "Success in epsoide 188, used 175 iterations!\n",
            "now epsilon is 0.01, the reward is -37.98501745082509 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 189, used 162 iterations!\n",
            "now epsilon is 0.01, the reward is -83.10139588824379 maxPosition is 0.5299986959083577\n",
            "Success in epsoide 190, used 170 iterations!\n",
            "now epsilon is 0.01, the reward is -52.98131868453493 maxPosition is 0.5420727081567481\n",
            "Success in epsoide 191, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -65.72608509223707 maxPosition is 0.5059110852620284\n",
            "Success in epsoide 192, used 130 iterations!\n",
            "now epsilon is 0.01, the reward is -78.62084691999395 maxPosition is 0.5194754669879666\n",
            "Success in epsoide 193, used 127 iterations!\n",
            "now epsilon is 0.01, the reward is -75.90684990050894 maxPosition is 0.523781809945515\n",
            "Success in epsoide 194, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -71.80176829816064 maxPosition is 0.5410568598079735\n",
            "Success in epsoide 195, used 167 iterations!\n",
            "now epsilon is 0.01, the reward is -55.63800317068407 maxPosition is 0.5148578023258621\n",
            "Success in epsoide 196, used 87 iterations!\n",
            "now epsilon is 0.01, the reward is -23.91501569530319 maxPosition is 0.5120699741011052\n",
            "Success in epsoide 197, used 166 iterations!\n",
            "now epsilon is 0.01, the reward is -55.939839733060424 maxPosition is 0.5073104074802237\n",
            "Success in epsoide 198, used 179 iterations!\n",
            "now epsilon is 0.01, the reward is -37.99666481569602 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 199\n",
            "now epsilon is 0.01, the reward is -16.67182122231914 maxPosition is 0.5265758293781637\n",
            "Success in epsoide 200, used 88 iterations!\n",
            "now epsilon is 0.01, the reward is -24.83459812280569 maxPosition is 0.5076781715258969\n",
            "Success in epsoide 201, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -75.15674052897663 maxPosition is 0.5085997726226963\n",
            "Success in epsoide 202, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is -61.13933482968207 maxPosition is 0.5410568598079735\n",
            "Success in epsoide 203, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -80.84984710671516 maxPosition is 0.5085997726226963\n",
            "Success in epsoide 204, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -80.85759504039916 maxPosition is 0.5085997726226963\n",
            "Success in epsoide 205, used 93 iterations!\n",
            "now epsilon is 0.01, the reward is -22.33847513751053 maxPosition is 0.503868742267953\n",
            "Success in epsoide 206, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -74.81715088926126 maxPosition is 0.5166396828127509\n",
            "Success in epsoide 207, used 88 iterations!\n",
            "now epsilon is 0.01, the reward is -27.261960981253576 maxPosition is 0.5065973084882786\n",
            "Success in epsoide 208, used 101 iterations!\n",
            "now epsilon is 0.01, the reward is -13.158724931158874 maxPosition is 0.5013967129052416\n",
            "Success in epsoide 209, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -73.80486654839834 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 210, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -79.8333163214012 maxPosition is 0.522362669739683\n",
            "Success in epsoide 211, used 157 iterations!\n",
            "now epsilon is 0.01, the reward is -65.74253184921082 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 212, used 140 iterations!\n",
            "now epsilon is 0.01, the reward is -78.82287025908222 maxPosition is 0.5401072729948353\n",
            "Success in epsoide 213, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -76.54593008132656 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 214, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -62.949009582930756 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 215, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -80.05474229433204 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 216, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -81.92756454955105 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 217, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -69.40855655137861 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 218, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -68.46990737736753 maxPosition is 0.5308428942261745\n",
            "Success in epsoide 219, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -54.076656619498344 maxPosition is 0.5308428942261745\n",
            "Success in epsoide 220, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -65.45414819501772 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 221, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -55.61489195044947 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 222, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -70.27781216906936 maxPosition is 0.5165977389186027\n",
            "Success in epsoide 223, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -78.10918541100463 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 224, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -82.52481763123757 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 225, used 140 iterations!\n",
            "now epsilon is 0.01, the reward is -78.37696695749406 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 226, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -85.312680050111 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 227, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is -93.31323001277084 maxPosition is 0.5176366276915942\n",
            "Success in epsoide 228, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -77.03547961001556 maxPosition is 0.5004976634543191\n",
            "Success in epsoide 229, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -79.36986995259899 maxPosition is 0.5003926944249626\n",
            "Success in epsoide 230, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -71.98083032967057 maxPosition is 0.5207926520545703\n",
            "Success in epsoide 231, used 104 iterations!\n",
            "now epsilon is 0.01, the reward is -6.933437694563313 maxPosition is 0.5081502684146746\n",
            "Success in epsoide 232, used 143 iterations!\n",
            "now epsilon is 0.01, the reward is -79.76041775871954 maxPosition is 0.5251522845074619\n",
            "Success in epsoide 233, used 140 iterations!\n",
            "now epsilon is 0.01, the reward is -81.28233524868406 maxPosition is 0.5255391526303459\n",
            "Success in epsoide 234, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -73.80070103819077 maxPosition is 0.5063586906822063\n",
            "Success in epsoide 235, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -71.29492997926633 maxPosition is 0.5166396828127509\n",
            "Success in epsoide 236, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -68.70445197609573 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 237, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -80.32848018476017 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 238, used 141 iterations!\n",
            "now epsilon is 0.01, the reward is -75.9711198597362 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 239, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -79.8759724012666 maxPosition is 0.5308428942261745\n",
            "Success in epsoide 240, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -79.76214688581963 maxPosition is 0.538026647699457\n",
            "Success in epsoide 241, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -79.69756411681537 maxPosition is 0.5242512551385875\n",
            "Success in epsoide 242, used 139 iterations!\n",
            "now epsilon is 0.01, the reward is -80.54005732475527 maxPosition is 0.5336298250452571\n",
            "Success in epsoide 243, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -81.43345373764134 maxPosition is 0.5350419276532614\n",
            "Success in epsoide 244, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -84.27724713913 maxPosition is 0.5412763951127125\n",
            "Success in epsoide 245, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -72.96199572233326 maxPosition is 0.5439879687533824\n",
            "Success in epsoide 246, used 174 iterations!\n",
            "now epsilon is 0.01, the reward is -49.98330725070454 maxPosition is 0.5177986277599554\n",
            "Success in epsoide 247, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -59.34302066469308 maxPosition is 0.5308428942261745\n",
            "Success in epsoide 248, used 158 iterations!\n",
            "now epsilon is 0.01, the reward is -70.81468269002912 maxPosition is 0.5187763341668327\n",
            "Success in epsoide 249, used 162 iterations!\n",
            "now epsilon is 0.01, the reward is -66.03981922016763 maxPosition is 0.5392951146836421\n",
            "Success in epsoide 250, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -79.49490274641757 maxPosition is 0.5065424814871503\n",
            "Success in epsoide 251, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -76.61268393259682 maxPosition is 0.5155575530804452\n",
            "Success in epsoide 252, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is -58.68757423576222 maxPosition is 0.5139682935927048\n",
            "Success in epsoide 253, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -73.99230930833852 maxPosition is 0.537928661806401\n",
            "Success in epsoide 254, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -92.340103732497 maxPosition is 0.5189528644660528\n",
            "Success in epsoide 255, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -83.19607202390804 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 256, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -77.13533880164019 maxPosition is 0.5247840243684146\n",
            "Success in epsoide 257, used 143 iterations!\n",
            "now epsilon is 0.01, the reward is -83.30242125298756 maxPosition is 0.510161864450921\n",
            "Success in epsoide 258, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -80.81238598927602 maxPosition is 0.5084094762493209\n",
            "Success in epsoide 259, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -76.96868670746235 maxPosition is 0.5132621864268028\n",
            "Success in epsoide 260, used 157 iterations!\n",
            "now epsilon is 0.01, the reward is -61.43917644086298 maxPosition is 0.5267486208648002\n",
            "Success in epsoide 261, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -62.743644248479114 maxPosition is 0.5129313327463645\n",
            "Success in epsoide 262, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -82.73996707231152 maxPosition is 0.5129313327463645\n",
            "Success in epsoide 263, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -79.60153501777634 maxPosition is 0.5308208934604665\n",
            "Success in epsoide 264, used 158 iterations!\n",
            "now epsilon is 0.01, the reward is -61.965548333601106 maxPosition is 0.5265599227388905\n",
            "Success in epsoide 265, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -66.51258908035798 maxPosition is 0.5083237134704968\n",
            "Success in epsoide 266, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -86.0021809812377 maxPosition is 0.5390480877911089\n",
            "Success in epsoide 267, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -78.30932041914767 maxPosition is 0.5280497358063352\n",
            "Success in epsoide 268, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -64.28393228622255 maxPosition is 0.5280497358063352\n",
            "Success in epsoide 269, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -71.27230133143038 maxPosition is 0.5363355594652481\n",
            "Success in epsoide 270, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -72.57382851024516 maxPosition is 0.5267326401628566\n",
            "Success in epsoide 271, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -81.93576481896346 maxPosition is 0.5194582566518284\n",
            "Success in epsoide 272, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -78.10094829606659 maxPosition is 0.5093493994318118\n",
            "Success in epsoide 273, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -77.84542427445113 maxPosition is 0.5084975975561904\n",
            "Success in epsoide 274, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -86.23915270412323 maxPosition is 0.5220807675568678\n",
            "Success in epsoide 275, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -76.30761476485891 maxPosition is 0.5177635863917314\n",
            "Success in epsoide 276, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -72.27128864636943 maxPosition is 0.511886605750671\n",
            "Success in epsoide 277, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -62.274699780343994 maxPosition is 0.5328313831171091\n",
            "Success in epsoide 278, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -72.59838396990996 maxPosition is 0.5375706147001993\n",
            "Success in epsoide 279, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -54.54454365192372 maxPosition is 0.5334975608446889\n",
            "Success in epsoide 280, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -76.37664756103182 maxPosition is 0.5261389361258347\n",
            "Success in epsoide 281, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -53.73631823628982 maxPosition is 0.5129830739980799\n",
            "Success in epsoide 282, used 179 iterations!\n",
            "now epsilon is 0.01, the reward is -107.12437004678151 maxPosition is 0.5003236798891666\n",
            "Success in epsoide 283, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -76.70984326626619 maxPosition is 0.5304931363223288\n",
            "Success in epsoide 284, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -71.91485747198574 maxPosition is 0.5286273440555747\n",
            "Success in epsoide 285, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -66.1945685623095 maxPosition is 0.535117151294528\n",
            "Success in epsoide 286, used 173 iterations!\n",
            "now epsilon is 0.01, the reward is -43.26116642146287 maxPosition is 0.5249243781121892\n",
            "Success in epsoide 287, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -73.94122097509828 maxPosition is 0.5169798852218522\n",
            "Success in epsoide 288, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -62.20350812004151 maxPosition is 0.5015101652786697\n",
            "Success in epsoide 289, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -78.66922918550051 maxPosition is 0.5201182684796186\n",
            "Success in epsoide 290, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -72.04147785344989 maxPosition is 0.5220331331208288\n",
            "Success in epsoide 291, used 169 iterations!\n",
            "now epsilon is 0.01, the reward is -98.12859438730896 maxPosition is 0.5278345254810524\n",
            "Success in epsoide 292, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -76.60484180652077 maxPosition is 0.5230915353742135\n",
            "Success in epsoide 293, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -72.93197215520512 maxPosition is 0.524268947914285\n",
            "Failed to finish task in epsoide 294\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5965959368907244\n",
            "Success in epsoide 295, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -61.38768247529886 maxPosition is 0.5318011427199009\n",
            "Success in epsoide 296, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -73.89160534661868 maxPosition is 0.524978204459564\n",
            "Success in epsoide 297, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -68.29975414882476 maxPosition is 0.5125763681013786\n",
            "Success in epsoide 298, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -75.09846740749441 maxPosition is 0.5000315245157347\n",
            "Success in epsoide 299, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -65.02616428006247 maxPosition is 0.5041207359090254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heg2vTwTU-SY",
        "colab_type": "code",
        "outputId": "983d10f2-e9e4-4a25-e5bd-c89ba573bdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Test\n",
        "env = gym.make('MountainCar-v0')\n",
        "model=keras.models.load_model('bestDQNnet.h5')\n",
        "\n",
        "state = env.reset().reshape(1, 2)\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "done = False\n",
        "i = 0\n",
        "while not done:\n",
        "    Q = model.predict(state)\n",
        "    action = np.argmax(Q[0])\n",
        "    img.set_data(env.render(mode='rgb_array')) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    state, reward, done, _ = env.step(action) \n",
        "    state = np.reshape(state, (1,2))\n",
        "    i = i + 1   \n",
        "print('run for: %i steps' %(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run for: 157 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAADnCAYAAABBu67aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deVyN+eIH8M9ptxSKSfbJMiNLZAuDbJPKFq2k7KQxDF0TF3Mvri37UmKYFpSlZOdlT8KYm90gBjOUhorTSuec5/eHX1071Tk9Z/m8X695ve5Uc56PuePj+3y/3+f7SARBABERlZ2e2AGIiLQFC5WISElYqERESsJCJSJSEhYqEZGSGHzi+9wCQET0Lsn7vsgRKhGRkrBQiYiUhIVKRKQkLFQiIiVhoRIRKQkLlYhISVioRERKwkIlIlISFioR6YTNmzfg4sVvIZUeQW7uf5GffwPKPr70U09KERFphXv37sDK6ggUiiMAAH39qjAzcwQAVK7cGVWquAAADA1rQk+vYqmuwUIlIp0klz9DVtY2AEBW1g48fDgVAFClSj8YGdWFnl4FWFnNKlG5slCJiCBB0QyoRGIIicQIEolRiT+FhUpEOkgCff2qxbf5r275nQEABgY1oKdXoVSfykIlIp0gkRjAzKwXmjSZAX19c+jpmcDYuAkkkvceHFUqLFQi0gl6epVgbR0DU1ML1V1DZZ9MRKRjWKhERErCQiUiUhLOoRKR1hIEofhpqKL/fe/ePZw+ffqNn2vatCnatWtX5utJPvHoFd8pRUQaITs7G4mJiW987e7du1i/fj0A4O+//4aFhQVycnLw559/vvFzkyZNwooVK0pyufduDeAIlYg0hlQqxa1bt/D8+XMsXrwYhYWFxd/Lzc3FhQsXPvrPp6enqzQfC5WINMbFixfh4OCg9M89fPgw0tPTYWlpWabP4aIUEWmMRo0aoVmzZkr/3Lt37yI3N7fMn8NCJSKNUbt2bTRo0EDsGB/EQiUiUhLOoRKRTtDT00ODBg2gr69f/LXHjx8jOztbaddgoRKRRjMxMYG5uXnx30ulUuTk5LzxM/r6+qhatSrc3NxQseL/zjf966+/sGPHDmRnZ+Pnn3/G/Pnzy5SFhUpEGmXo0KE4cOAABEFAixYt0L59e9SpU6f4+6mpqdi+fTueP39e/LUOHTrA2Nj4nc+qU6cOPD09sW3bNvzxxx9lzsY5VCLSKC1atAAAVKpUCX369EHdunUhkUiK/6pVqxY8PT1RpUoVAICpqSlat24NPb13667o5+3t7ZWSjYVKRBpHIpGgffv2b9y+v/49Kysr9OjRAwBgZmaG6tWrf/SzOnTogIEDB5Y5F2/5iUjjVKpUCW3btv3g4dASiQSNGjXC8OHD0a9fP1y9evWjn9epUyf06dOnzLlYqESkUUxNTdGnTx9YWVlBKpV+8OfatWsHd3d3yGQyvHjx4p0DUYro6enBwkI5h07zlp+INEr9+vWxfft2tGzZ8qM/VzSHamBggC5dusDMzOydn9HX10e3bt1gZ2enlGwsVCLSSDY2Nqhatep7v1exYkV06NCh+O9r166Nli1bolq1ajA3Ny/eatWtWzd88803b+xNLQse30dEGkkQBDx+/BixsbHIysqCQqGAkZERmjRpAhsbm+Lb+PT0dISFheG3335D06ZNYWJigkePHqF27drFOwPe5urqWjwCNjExed/o9r2TtyxUItJYgiCgsLAQycnJyMjIwN27d5GVlYVLly7h6NGjAACFQoG8vLwSfa6JiQkMDF4tMdnY2KBfv3744osv4OPjAwCoWLEiC5WItIcgCLhx4wbOnTuH+/fvY9OmTcjKykJ+fj4AFI88zc3N0b9//xK9LjohIQF3795941qGhoaoUaMGAODRo0c8YJqINF92djZOnTqFQ4cOITY2Fo8fPy7+nq2tLerUqYPOnTujf//+AABjY2M0bNiwRIX68OHD4ietLl26hOjoaEil0g/uFCjCESoRqT1BEHDp0iXcuHEDy5YtQ3JyMgDA0tISX375JaytrTFu3Dh89dVXZT4k+kNycnKKr9u1a1fe8hORZpHJZLh58yYWLlyI+Ph45ObmwsjICPXr14ejoyNGjRoFW1tbACjRCFQJWKhEpBlevnyJ27dvIzg4GDExMXj58iUsLCzQsGFD/PDDD3Bzc4Oent57n88vJyxUIlJvgiDg6tWrWLt2LTZv3oz8/HyYmZlhzJgxmDhxIqpXr/7e5/dFwEIlIvUkCAJevnyJ7du3Y86cObhz5w7Mzc0xbNgwTJkyBbVr11ba5nslYaESkXo6ffo0AgICcOPGDdSoUQPu7u6YNGkSrK2ty3tu9HNx2xQRqRepVIrAwEDs2bMHT548Qdu2bREcHIyuXbuKHa1U+Cw/EZU7QRCwb98+9O3bFxs2bICZmRl27NiBhIQEjS1TgLf8RFTOMjMzMW/ePISHhyMnJwcBAQEYM2YMmjZtqq639+/DW34iEo9CocDTp08xfPhwHDp0CM2bN8fEiRMxYsSI4ufmNR1HqESkcoIgYMuWLQgMDERWVhY8PDwwe/ZsNG7cWOxopcURKhGJY8uWLfD390dhYSGCg4MxYcIErRmVvk77fkVEpDbS0tIwYcIEHDt2DHZ2dli8eDHatm2rbntKlYaFSkQqkZqaCk9PTyQmJqJr166IiYmBlZWV2LFUitumiEipZDIZ1q9fjwEDBuDixYuYN2+eTpQpwBEqESmRXC5HSEgIAgMDYWhoiLCwMAwZMkTMQ0zKlW78KolI5QRBQEhICKZNm4aOHTti48aN8Pb21pkyBbhtioiUQBAErFmzBj/++CN69OiByMhImJubix1Lld67bUp3/uggIpWQy+VYvXo1fvzxR/Ts2RMRERHaXqYfxDlUIiq1lJQUTJs2DQcPHkTv3r0RHh5e/PpmXcRCJaJSSUlJgaurK27cuAFnZ2edHpkW4S0/EZXKzJkzkZqaip9++kkX5kw/C0eoRPTZBEHA/fv3cfjwYTx58gRRUVFwcnLSqZX8j2GhEtFnu3//PgYPHoz79+8jMjISzs7OmnTknsrxjxUi+ix37tzBoEGD8ODBA0RERKBv374s07dwhEpEn5SSkoLBgwfj4cOHiIiIQL9+/cSOpJZYqET0UUWr+ampqYiKioKzs7PYkdQWC5WIPqjoNj81NRWbN2+Gk5MTb/M/goVKRO8lCAImTpyIa9euYcmSJejTpw/L9BO4KEVE7yh6Nv/UqVNwcXHBiBEjuDXqM3CESkRvKDqCj8/mlxz/yCGiYjKZDGvXrsW0adPQs2dPhIeHs0xLgIVKRAD+V6b/+Mc/0KNHD0REROj0QSelwUIlIsjl8jdGplFRURyZlgIPmCYiXLhwAd988w2qVKmCq1evwtLSUuxI6o4HTBPRu9LS0hAYGAgjIyMsW7YMNWrUEDuSxuIqP5EOS0tLg5eXFy5evIjQ0FAMHTqUe03LgIVKpKNSU1Ph6emJS5cusUyVhHOoRDooOzsbTk5OSEpKwqZNm+Dn58cyLRnOoRIRoFAoEB8fjwsXLqBjx45wcXFhmSoJC5VIhwiCgC1btsDf3x9t2rTB9u3buQilRCxUIh2yefNm+Pv7o1WrVti5cydq164tdiSt8tFCPXXqFAoKCsorCxGpUEZGBpYuXQqFQoEpU6agVq1aYkfSOh8t1O7du2PGjBnIz88vrzxEpAKZmZnw8/PD7du3sXjxYgwcOFDsSFrpo4Xq4eGB5cuXY+7cueWVh4iULDMzE8OGDcOxY8ewePFiBAQE8Cg+Ffnov9Xvv/8elpaWiI6OxrVr1/CJLVZEpGYUCgXWrl2LAwcOwNHRERMmTOCKvgp9dB+qIAhCQkICPDw8UK1aNezatQtff/01/w8h0gCCIODAgQMYNmwYatWqhV27dqFx48Zix9IW7y3BT27sFwQBMTExGDJkCOzs7HDu3DkYGhqqJiIRKc2+ffvg6+uL2rVrIzY2Fk2aNBE7kjYp3cZ+iUQCZ2dneHl54dq1a1i8eDEKCwuVH4+IlEYqlWLJkiXIyclBQEAAy7ScfNaz/FWqVMG6desgCALmzJkDQRAwbdo0GBkZqTofEZWQVCpFQEAAzp49i5kzZ2L06NFiR9IZJXqW/88//0SrVq2Qm5uLCxcuoGXLlqpNR0QlIggCRo4cifDwcAQFBWHevHnQ19cXO5Y2Kvuz/HXr1kV4eDgqVKgAX19f/PHHH8qJRkRlJggCkpKSsH//fjRq1Ah+fn4s03JW4tOmFAoF9u3bBx8fHzRu3Bjx8fGoW7eu6hIS0Wc5d+4cBg8eDENDQ+zevRstW7bkjhzVUc5pU3p6enByckLXrl2RnJyMHTt2cH8qkchevHiB0NBQpKamwsvLC7a2tixTEZTqcQlDQ0OEh4ejT58+mDVrFtatWweFQqHsbET0GfLz8xEYGIitW7fiu+++w+zZs8WOpLPKdMB0UlISHB0dUaVKFVy4cAFWVlbKTUdEnzRz5kzMnz8fHh4e+OWXX1ChQgWxI+kC5R8w3bFjR6xevRpZWVnw8vJCWlpaWT6OiEooOTkZmzdvhpWVFb7//nuWqcjK/AoUhUKB8PBwjB07Fp06dcLu3btRrVo15SUkove6desWnJ2d8ezZM+zbtw/29vacNy0/qnkFip6eHgYMGIA2bdrg7NmzOHjwIBepiFRMLpcjMjIS9+7dQ79+/dC+fXuWqRpQyhleFhYW2LlzJ9q0aYNx48Zh27ZtyvhYInoPuVyOefPmYcmSJRg6dCjWrFnD/aZqQqlvPY2OjsaIESPQokULHD58GObm5mVLR0TvSElJQefOnSGXy3H06FG0bt1a7Ei6SPVvPfX09MSCBQtw7do1jBo1CllZWcr8eCKdl5KSAjc3N8hkMkRERLBM1YxSC1VPTw+TJk1C+/btER8fz03/REokk8mwaNEiXLlyBUOHDoWLi4vYkegtSr3lB149T3znzh0MGjQIaWlp2Lp1K3r37s0Jc6IykMlkWLt2LaZNm4ZevXohKiqKU2riKt0B06W92unTp+Hg4AArKytcvXqVW6mIymD16tUIDAxEjx49sGXLFpap+FQ/h/q69u3bIygoCOnp6fjhhx+Qm5urqksRabW0tDSEhYXB0NAQ3333HctUjX3WAdOlYWxsjNmzZ+PevXuIjIxEzZo1sXDhQlVdjkgrFR128ueffyIsLAxOTk5iR6KPUOm7ZI2NjREYGIgvv/wSUVFRSExMVOXliLSKQqHA5s2bi6fPhgwZwtc/qzmVzaEWf4Ag4PLly+jZsydMTExw5MgR2NjYlPVjibSaXC7H1q1b4e/vjzZt2iAmJoaHD6mX8p1DLb6qRILmzZvD29sbjx8/xvr16/Hy5UtVX5ZIo6Wnp2Py5MkoLCzEypUrWaYaQmVzqG9cxMAAS5cuhVwuL35MLjg4mLcvRO/x/PlzjBo1ClKpFEuXLkXz5s3FjkSfSeW3/K+7fPkyHB0dIQgCTpw4gaZNm3J/KtFrBEFAfHw83N3d0axZMxw7dgzVq1cXOxa9S5xb/tfZ2toiOjoaEokErq6uuH79enlenkjt7d27F6NGjULz5s0RGxvLMtUw5X7P3b17d3h5eeH27dtYvnw551OJ/p9UKsV//vMf5ObmYurUqWjUqJHYkaiEymUO9W1z585Feno6IiMjUb9+fQQFBcHIyEiMKERqIScnB+PHj8elS5cwc+ZMDBkyROxIVArlOof6ur///hvNmzdHZmYmzp49i3bt2qnqUkRqTRAEbNq0CWPGjEHHjh2RkJDA803Vn/hzqK+rXr06Nm7cCFNTU4wdOxb37t0TKwqRaARBQFJSEmbNmgVra2uEhoZy94sGE22ECrz6j2nVqlWYPHkyvv32Wxw6dIir/qRTnj17hlatWuHBgwc4fvw4unfvLnYk+jzqNUIFXm369/HxgZOTExITExEaGgqFQiFmJKJyk5+fj5kzZ+LRo0eYNGkS7O3txY5EZSTqCLXI06dP0bNnT6SkpGDLli1wdXUtj8sSiWr27NmYN28e3N3dER4ezldAaxb1G6EWqV69OqZMmQKJRILly5cjLS1N7EhEKpWcnIzIyEhYWVlh8uTJLFMtoRYjVODVyTrh4eEYM2YMOnXqhL1796Jq1arldXmicnPr1i04OTnh2bNn2L9/P+zt7bl2oHnUd4QKvHofVf/+/dGuXTucP38eBw4c4HwqaR25XI7IyEjcv3+/+L93lqn2UJsRapE7d+4Uv8nxt99+w1dffVXeEYhUQi6XY+7cuZg/fz68vLwQGhqKSpUqiR2LSke9R6hFGjRogDlz5qCwsBDTpk1DZmam2JGIlOLevXtYt24dzMzMMHnyZJapFlK7QjUwMMD333+Pf/zjH9izZw8mTpzIV1GTxktJScGgQYNQWFiIiIgI2NnZiR2JVEDtChUA9PX1MWLECLRs2RKHDh3CoUOHWKqksQoLCxEcHIyrV6/Cy8sLzs7OYkciFVG7OdTiCwsC7t69iz59+iArKwu7du1C165dxYpDVGqhoaGYNGkSunTpgp07d/KV6tpBM+ZQi0gkEjRq1Ag+Pj549uwZ1q1bh7y8PLFjEZXIo0ePsGHDBhgZGcHf359lquVEOb6vJKZPn47CwkIsWrQIhoaGCA0NRcWKFcWORfRJaWlp8PT0xO3bt7F+/Xo+AagD1HaEWsTY2BgTJkxA3bp1ERMTg19//VXsSESfJAgC4uLicObMGXTs2BHu7u48kk8HqO0c6tuSk5Ph7u6O/Px8bNu2DV26dBE7EtF7KRQKbN68GQEBAWjbti2io6NRs2ZNsWORcr13DlVjClUQBKxduxaTJ09G165dsX//fj7/TGrpyZMnsLOzQ0ZGBg4fPsw//LWTZi1KvU0ikWDs2LHw9/fH6dOnMX36dLx48ULsWERvyMjIwLBhw/DkyRMEBwejc+fOYkeicqQxI9QiBQUFaNeuHX7//Xfs2LEDAwcO5LPQpBakUik8PT1x5MgRLFu2DAEBAZw31V6aPUItYmxsjDVr1qB69eqYPn06fv/9d276J9EJgoDjx4/j6NGjsLGxgbe3N8tUB2ncCLXIrl27MGjQIDRv3hznz5/nVioS1e7duzF8+HA0aNAAO3fuRMOGDcWORKqlHSPUIj169IC3tzdu376NpUuX4uXLl2JHIh0llUqxcOFC5OXlYfLkySxTHab2G/s/pEqVKggLCwMAzJ07FwqFAtOnT4eRkZHIyUiXZGdnY/z48UhOTsasWbPg4+MjdiQSkcbe8hdJT09HixYtkJmZibNnz6Jdu3ZiRyIdIQgCwsPDMXLkSNjb2yMxMZHzprpDu275i9SoUQObNm2CqakpxowZgz/++EPsSKQDBEHAmTNnMGPGDDRq1Ajr16+Hnp7G/3aiMtL4ESrw6smUlStXYsqUKXB0dMTBgwe5lYpU6vnz57C1tcWDBw9w7Ngx9OjRQ+xIVL60c4QKvHofla+vL5ydnZGQkICQkBBupSKVyc/Px4wZM/Do0SNMmjQJHTt2FDsSqQmtGKEWycjIQPfu3XHnzh1ER0djwIABYkciLZOXl4fAwED8/PPPCAgIwPz58/kItG7S7Gf5P1dkZCQmTJgAOzs7bNu2DVZWVmJHIi1y/Phx9OrVC/Xr10dycjLPN9VdulGogiAgKioK/v7+aN26NXbs2MFSpTITBAEXL17E4MGDUVhYiJ07d6JDhw6cq9dd2juH+jqJRAIfHx/4+PjgzJkzmDNnDhQKhdixSMPJ5XJ89913ePDgAebMmcMypffSukIFXi1SzZo1C/b29oiKikJMTAwXqajU5HI55syZg99++w3Dhg2Dp6cny5TeSysLFQDq1KmDnTt3wtbWFuPHj8fWrVtZqlRihYWF+Pe//42FCxfC29sba9asQaVKlcSORWpK6+ZQ3xYfH48hQ4agUaNGOHnyJMzNzcWORBrkxo0b6NSpEwwMDJCQkAAbGxuxI5F60I051LcNGDAACxcuREpKCoYPH46srCyxI5GGuHnzZvG7oKKiotC0aVOxI5Ga0/oRKvDqSarly5cjMDAQ/fv3x/bt22FsbCx2LFJjjx49Qu/evXHv3j3ExcWhT58+nDel1+nmCBV4tUjl7u6OZs2a4fjx4zh+/DjnU+mD5HI5YmJicPPmTfTu3RvdunVjmdJn0YlCBYB69eohLi4OdevWhY+PDw4dOsRSpXcIgoDVq1fjn//8J/r27YuIiAgeXk6fTSdu+V935coV2Nvbo2LFivj1119hbW0tdiRSEwqFAqtXr0ZQUBC+/fZbhIeH80ko+hDdveV/3ddff43AwEBIpVL861//QnZ2ttiRSE2kpqYiODgYRkZGCAoKYplSiWnsif2lZWRkhNmzZ0NPTw8LFiwAAISEhKBy5coiJyMxPXz4EB4eHnj+/DnWr18Pe3t7sSORBtK5QgUAAwMDzJo1CwUFBVi0aBEMDAzw888/84BgHfXw4UO4ubnh+vXrWL9+Pby8vLgIRaWisw2ir68PPz8/WFtbY+/evTh//jwXqXSQQqHATz/9hPPnz2P48OF8rJTKROcWpd6WnJyMQYMGQSaT8QQhHfP6yWR2dnbYvn07Tyajz8VFqfexs7NDbGwsDAwM4ObmhqSkJLEjUTkQBAGRkZEICAhA27ZtWaakFDo/Qi1y7tw5ODg4wMLCAmfPnkW9evXEjkQqdPLkSfTr1w81atRAUlISatasKXYk0iwcoX5Mq1atMHr0aPz9999YunQp8vPzxY5EKpKRkYHFixdDLpcjMDAQlpaWYkciLaGTq/zvY2JigqVLl0JPTw8hISEAgEWLFsHExETkZKRMGRkZGDp0KE6dOoWlS5fC39+fc+akNCzU1xgbG2PJkiUQBAGhoaGQSCRYvHgxjIyMxI5GSpCRkYEhQ4YUl+m4ceNYpqRULNS3GBkZITg4GIIgYO3atZBIJFi0aBFLVcO9PTIdN24c9PX1xY5FWoaLUh+Ql5cHFxcXnD59GitXrkRAQIDYkaiUnj59Cl9fX5w4cQJLlizBuHHjYGDAsQSViW689VSZTp48CW9vb1SuXLn4dSqkWYr2mvr5+cHe3h4nTpzgvDgpAwu1NBISEuDl5YUKFSogNjYWrVq1EjsSfSZBELB7926MHDkS1tbWiI2NRf369cWORdqBhVoagiAgKSkJ7u7uMDExQVxcHEtVAygUCuzbtw++vr5o2LBhcZlyEYqUhIVaWoIg4MyZM3B3d0flypURFxeH5s2b8zenmlIoFNi/fz98fX1Rv359xMXF8dxbUjZu7C8tiUSCzp07Y9u2bcjJycHgwYNx48YNHqaihgRBKB6Z1qtXD7GxsSxTKjcs1M8kkUjQpUsXxMTEQCqVwtXVFdevXxc7Fr1lz5498PPzKx6ZNmzYUOxIpENYqCUgkUjQrVs3xMTEIDs7G66urrh8+bLYsej/xcfHY8SIEbC2tsauXbtYplTuWKil4ODggIMHD6J169YYNGgQLl26JHYknfb2an5cXBy+/PJLsWORDuKiVBkkJSXBzc2Nq/8iKlrNHzduHBo0aICYmBjUq1ePC4akalyUUraOHTtix44dKCgogJubG65cucKFqnJUVKZ+fn745ptvcOLECW6NIlFxhFpGgiDg9OnT8PT0hKmpKXbt2gUbGxv+plYxQRCwd+9e+Pn5oW7dupwzpfLGEaoqFK3+R0dHQyqVYtCgQbh+/TpHqir09OlThIWFFa/ms0xJXXCEqkRFz/4bGhrCw8MDc+fORYUKFcSOpVWePn0KPz8/HDhwAHZ2dtixYwf3mZIYOEJVNQcHB2zbtg0ymQzLli1DUFAQ8vLyxI6lNTIyMopPjXJwcOCmfVI7LFQl69KlC3bv3o3Ro0cjJCQE06dPR0FBgdixNF7ReaZFR/AdO3aMB52Q2uGhkEomkUjQrl072NrawtjYGCEhIXj69CkmTpzIV1SXglwuR1xcHEJDQ5GUlFR8OLSeHscCpH44h6pCBQUFCAwMREhICGrVqoWdO3eyVEug6FXP/v7+kMvlWLZsGQ+HJnXB06bEkJeXh3nz5mHLli2Qy+VYuHAhBg4ciMqVK4sdTa2lpqZi27ZtmDVrFpo0aYKxY8di9OjRLFNSFyxUMf33v/+Fu7s77t+/j2HDhmHNmjUwNTUVO5ZaevToEby8vJCYmAgHBwdER0ejZs2aYscieh1X+cXUpk0bxMXFoW3btoiOjoaTkxP279/P/aqvkclkWLVqFZycnHD58mU4OzuzTEmjcIRajgRBgFwux9y5c7FgwQKYmpoiIiIC3bp10/nRakZGBiIiIhAUFARjY2OEhYXBy8uLi0+krnjLry5kMhkiIiKwYsUK3Lp1C46Ojti4cSOqV6+ucwVSWFiIO3fuwMPDAzdv3kSvXr0wYcIEuLi46Ny/C9IoLFR1c/v2bbi6uuLWrVswNzfHihUr4OHhoRMLL4IgQCaTYd68eVi5ciWys7Ph4uKCiIgIVKtWTex4RJ/CQlVH6enp2LJlC6ZPnw4jIyN07twZ4eHhsLS01NrtVQUFBdizZw8WLlyIa9euwdTUFJs2bYKDgwOqVKkidjyiz8FCVVcymQwXL17ElClTkJiYiCZNmmDcuHFwc3NDvXr1xI6nVNeuXUNISAjCwsKgUCjg6+uLH3/8ETY2NmJHIyoJFqq6S01NRWxsLGbMmIGcnBx89dVX8PPzw9SpU2FkZCR2vFITBAEpKSlYuXIlYmNj8fTpU7Ro0QJBQUFwdnbW+QU50kgsVE0gCAKOHj2KVatW4dSpU8jNzcXAgQMxbdo02NrawsTEROyIJSKVSnH8+HGMHDkSWVlZsLCwgJ+fHxYsWABDQ0OtndYgrcdC1SQvX77EqVOnEBoaivj4eBgaGmLw4MFo0aIFxo8fj6pVq6ptGclkMvz111/YsGEDzp07h9OnT8PY2Bh+fn7w9/fH119/rRMLb6TVWKiaKCcnB4sWLcLGjRvx+PFjSCQSWFlZYfLkyRg5ciTMzMzUopyK9tjev38fGzZswIYNG5CVlQU9PT00a9YMMTExaNy4MQwNDcWOSqQMLFRNJQgCHj58iNDQUFy+fBmHDh2CQnUXUQ0AAAJ5SURBVKFAvXr10LRpU0ydOhW9evUCgHIftQqCgBcvXhSv2qelpeHx48eoXLkyHB0d0bNnTwwePBhffPFFueYiUjEWqjZ48eIFfv31V8yfPx8nT55EQUEBKlasCBsbG/Tt2xddu3aFpaWlSlfNBUHAhQsXkJubi6ioKFy8eBFXrlyBQqGAhYUFXFxcMHXqVLRo0UJtpyWIyoiFqk0UCgUSEhJw9epVrFq1Cnfu3Cn+npWVFWxtbVG7dm1MnDgREokENWrUgJWVVamudffuXeTm5iI3NxeLFi3CixcvkJiYiJycHACAvr5+8ap9w4YN0bZtW6X8GonUGAtVGwmCgMzMTOzfvx8HDx5EYmIi8vLykJmZCeB/UwA2Njaws7N74591cXFBp06d3vhaZmYmVqxYAblcXvy1I0eOID09vfh6AGBpaQlDQ0N4e3ujTZs2cHV15ao96RIWqrYrLCyEXC7HzZs3cfjwYTx+/Bi//PILBEHAy5cv33kVi4GBAfT19d/4WtHPvq5SpUrQ19dHxYoV4e/vDxMTEwwdOhQWFhYwNDR85zOIdAALVdfIZDI8f/4cAHD27FkcOXLkje+fOXMGV65ceeNrZmZm8Pb2fuNgEl9fXzRo0AASiQRVq1bloSVELFR6W0ZGRnHhFjEwMEDdunV56070cSxUIiIl4Yn9RESqxEIlIlISFioRkZKwUImIlISFSkSkJCxUIiIlYaESESkJC5WISElYqERESsJCJSJSEhYqEZGSsFCJiJSEhUpEpCQsVCIiJWGhEhEpyade6M5ThomIPhNHqERESsJCJSJSEhYqEZGSsFCJiJSEhUpEpCQsVCIiJfk/ZJuuCYDkHLkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNrk-_KBWXfp",
        "colab_type": "text"
      },
      "source": [
        "# Compiti\n",
        "\n",
        "Sono opzionali ... \n",
        "\n",
        "1.   provare a risolvere i due problemi scambando gli algoritmi: PG per la MountainCar e DQN per il CartPole\n",
        "2.   provare ad implementare un porblema con spazio delle azioni continuo (per esempio *CartPole_V1*)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT1d3pfLRFLn",
        "colab_type": "text"
      },
      "source": [
        "##DQN per il CartPole (pendolo inverso)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_04veG5xRMnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DQN algorithm\n",
        "# Dueling-DQN (DDQN) Implementation (più stabile rispetto a plain DQN)\n",
        "# https://arxiv.org/pdf/1511.06581.pdf\n",
        "\n",
        "# ci sono due reti neurali separate invece che una sola che fa entrambe le cose:\n",
        "# il Q-network che seleziona l'azione, e il target Q-network che valuta l'azione\n",
        "\n",
        "class DQN:\n",
        "    def __init__(self, env):\n",
        "        self.env=env\n",
        "        self.gamma=0.99 #discount rate\n",
        "        self.epsilon = 1\n",
        "        self.epsilon_decay = 0.05\n",
        "        self.epsilon_min=0.01\n",
        "        self.episodes=300 #numero di episodi\n",
        "        self.iterations=201 #200 è il limite imposto dall'environment\n",
        "        self.batch_size=32 #batch size quando si campiona memory\n",
        "        self.memory=deque(maxlen=20000)\n",
        "        \n",
        "        self.model_train=self.model()\n",
        "        self.model_target=self.model()\n",
        "        self.model_target.set_weights(self.model_train.get_weights())\n",
        "\n",
        "    def model(self): #modello rete neurale\n",
        "        state_shape = self.env.observation_space.shape\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(layers.Dense(24, activation='relu', input_shape=state_shape))\n",
        "        model.add(layers.Dense(48, activation='relu'))\n",
        "        model.add(layers.Dense(self.env.action_space.n,activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))\n",
        "        return model\n",
        "\n",
        "    def act(self, state): #calcola l'azione\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
        "\n",
        "        if np.random.rand(1) < self.epsilon: #parte random\n",
        "            action = np.random.randint(0, 2)\n",
        "        else: #parte non random\n",
        "            action = np.argmax(self.model_train.predict(state)[0])\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "    def replay(self): #replay \n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        samples = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        states = []\n",
        "        newStates=[]\n",
        "        for sample in samples:\n",
        "            state, action, reward, new_state, done = sample\n",
        "            states.append(state)\n",
        "            newStates.append(new_state)\n",
        "\n",
        "        newArray = np.array(states)\n",
        "        states = newArray.reshape(self.batch_size, 4)\n",
        "\n",
        "        newArray2 = np.array(newStates)\n",
        "        newStates = newArray2.reshape(self.batch_size, 4)\n",
        "\n",
        "        targets = self.model_train.predict(states)\n",
        "        new_state_targets=self.model_target.predict(newStates)\n",
        "\n",
        "        i=0\n",
        "        for sample in samples:\n",
        "            state, action, reward, new_state, done = sample\n",
        "            target = targets[i]\n",
        "            if done:\n",
        "                target[action] = reward\n",
        "            else:\n",
        "                Q_future = max(new_state_targets[i])\n",
        "                target[action] = reward + Q_future * self.gamma\n",
        "            i+=1\n",
        "\n",
        "        self.model_train.fit(states, targets, epochs=1, verbose=0)\n",
        "\n",
        "\n",
        "    def train(self, currentState, eps): #training\n",
        "        rewardSum = 0\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "            bestAction = self.act(currentState)\n",
        "\n",
        "            new_state, reward, done, _ = env.step(bestAction)\n",
        "\n",
        "            new_state = new_state.reshape(1, 4)\n",
        "\n",
        "            # Memorize\n",
        "            self.memory.append([currentState, bestAction, reward, new_state, done])\n",
        "\n",
        "            # Replay\n",
        "            self.replay()\n",
        "\n",
        "            rewardSum += reward\n",
        "\n",
        "            currentState = new_state\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if i >= 199:           \n",
        "            print(\"Success in epsoide {}, used {} iterations!\".format(eps, i))\n",
        "            self.model_train.save('./bestDQNnet.h5')\n",
        "\n",
        "        #Sync\n",
        "        self.model_target.set_weights(self.model_train.get_weights())\n",
        "\n",
        "        print(\"now epsilon is {}, the reward is {}\".format(max(self.epsilon_min, self.epsilon), rewardSum))\n",
        "        self.epsilon -= self.epsilon_decay\n",
        "\n",
        "    def start(self):\n",
        "        for eps in range(self.episodes):\n",
        "            currentState=env.reset().reshape(1,4)\n",
        "            self.train(currentState, eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBpKM7mCR5jI",
        "colab_type": "code",
        "outputId": "8f9a5785-e5c1-4afd-b5bb-4d2f8fa1f89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "dqn=DQN(env=env)\n",
        "dqn.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now epsilon is 1, the reward is 11.0\n",
            "now epsilon is 0.95, the reward is 21.0\n",
            "now epsilon is 0.8999999999999999, the reward is 13.0\n",
            "now epsilon is 0.8499999999999999, the reward is 22.0\n",
            "now epsilon is 0.7999999999999998, the reward is 26.0\n",
            "now epsilon is 0.7499999999999998, the reward is 14.0\n",
            "now epsilon is 0.6999999999999997, the reward is 13.0\n",
            "now epsilon is 0.6499999999999997, the reward is 13.0\n",
            "now epsilon is 0.5999999999999996, the reward is 14.0\n",
            "now epsilon is 0.5499999999999996, the reward is 13.0\n",
            "now epsilon is 0.4999999999999996, the reward is 13.0\n",
            "now epsilon is 0.4499999999999996, the reward is 11.0\n",
            "now epsilon is 0.39999999999999963, the reward is 12.0\n",
            "now epsilon is 0.34999999999999964, the reward is 13.0\n",
            "now epsilon is 0.29999999999999966, the reward is 9.0\n",
            "now epsilon is 0.24999999999999967, the reward is 12.0\n",
            "now epsilon is 0.19999999999999968, the reward is 11.0\n",
            "now epsilon is 0.1499999999999997, the reward is 11.0\n",
            "now epsilon is 0.09999999999999969, the reward is 11.0\n",
            "now epsilon is 0.049999999999999684, the reward is 8.0\n",
            "now epsilon is 0.01, the reward is 8.0\n",
            "now epsilon is 0.01, the reward is 8.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 9.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 9.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 9.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 9.0\n",
            "now epsilon is 0.01, the reward is 9.0\n",
            "now epsilon is 0.01, the reward is 9.0\n",
            "now epsilon is 0.01, the reward is 8.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 10.0\n",
            "now epsilon is 0.01, the reward is 8.0\n",
            "now epsilon is 0.01, the reward is 13.0\n",
            "now epsilon is 0.01, the reward is 28.0\n",
            "now epsilon is 0.01, the reward is 16.0\n",
            "now epsilon is 0.01, the reward is 38.0\n",
            "now epsilon is 0.01, the reward is 34.0\n",
            "now epsilon is 0.01, the reward is 21.0\n",
            "now epsilon is 0.01, the reward is 26.0\n",
            "now epsilon is 0.01, the reward is 22.0\n",
            "now epsilon is 0.01, the reward is 71.0\n",
            "now epsilon is 0.01, the reward is 64.0\n",
            "now epsilon is 0.01, the reward is 28.0\n",
            "now epsilon is 0.01, the reward is 48.0\n",
            "now epsilon is 0.01, the reward is 56.0\n",
            "now epsilon is 0.01, the reward is 54.0\n",
            "now epsilon is 0.01, the reward is 70.0\n",
            "now epsilon is 0.01, the reward is 50.0\n",
            "now epsilon is 0.01, the reward is 52.0\n",
            "now epsilon is 0.01, the reward is 31.0\n",
            "now epsilon is 0.01, the reward is 84.0\n",
            "now epsilon is 0.01, the reward is 31.0\n",
            "now epsilon is 0.01, the reward is 37.0\n",
            "now epsilon is 0.01, the reward is 62.0\n",
            "now epsilon is 0.01, the reward is 38.0\n",
            "now epsilon is 0.01, the reward is 69.0\n",
            "now epsilon is 0.01, the reward is 106.0\n",
            "now epsilon is 0.01, the reward is 47.0\n",
            "now epsilon is 0.01, the reward is 65.0\n",
            "now epsilon is 0.01, the reward is 43.0\n",
            "now epsilon is 0.01, the reward is 66.0\n",
            "now epsilon is 0.01, the reward is 55.0\n",
            "now epsilon is 0.01, the reward is 54.0\n",
            "now epsilon is 0.01, the reward is 73.0\n",
            "now epsilon is 0.01, the reward is 51.0\n",
            "now epsilon is 0.01, the reward is 85.0\n",
            "now epsilon is 0.01, the reward is 145.0\n",
            "now epsilon is 0.01, the reward is 77.0\n",
            "now epsilon is 0.01, the reward is 87.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 107.0\n",
            "now epsilon is 0.01, the reward is 118.0\n",
            "now epsilon is 0.01, the reward is 117.0\n",
            "now epsilon is 0.01, the reward is 157.0\n",
            "Success in epsoide 82, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 142.0\n",
            "now epsilon is 0.01, the reward is 171.0\n",
            "now epsilon is 0.01, the reward is 164.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 189.0\n",
            "now epsilon is 0.01, the reward is 184.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 149.0\n",
            "Success in epsoide 92, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 174.0\n",
            "now epsilon is 0.01, the reward is 193.0\n",
            "now epsilon is 0.01, the reward is 196.0\n",
            "now epsilon is 0.01, the reward is 185.0\n",
            "Success in epsoide 97, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 170.0\n",
            "now epsilon is 0.01, the reward is 159.0\n",
            "Success in epsoide 100, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 181.0\n",
            "now epsilon is 0.01, the reward is 158.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 179.0\n",
            "now epsilon is 0.01, the reward is 199.0\n",
            "now epsilon is 0.01, the reward is 161.0\n",
            "now epsilon is 0.01, the reward is 198.0\n",
            "now epsilon is 0.01, the reward is 184.0\n",
            "now epsilon is 0.01, the reward is 148.0\n",
            "now epsilon is 0.01, the reward is 163.0\n",
            "now epsilon is 0.01, the reward is 175.0\n",
            "now epsilon is 0.01, the reward is 156.0\n",
            "now epsilon is 0.01, the reward is 163.0\n",
            "now epsilon is 0.01, the reward is 138.0\n",
            "now epsilon is 0.01, the reward is 171.0\n",
            "now epsilon is 0.01, the reward is 164.0\n",
            "now epsilon is 0.01, the reward is 176.0\n",
            "now epsilon is 0.01, the reward is 187.0\n",
            "now epsilon is 0.01, the reward is 174.0\n",
            "now epsilon is 0.01, the reward is 174.0\n",
            "now epsilon is 0.01, the reward is 165.0\n",
            "now epsilon is 0.01, the reward is 157.0\n",
            "now epsilon is 0.01, the reward is 158.0\n",
            "now epsilon is 0.01, the reward is 156.0\n",
            "now epsilon is 0.01, the reward is 140.0\n",
            "now epsilon is 0.01, the reward is 149.0\n",
            "now epsilon is 0.01, the reward is 145.0\n",
            "now epsilon is 0.01, the reward is 169.0\n",
            "now epsilon is 0.01, the reward is 152.0\n",
            "now epsilon is 0.01, the reward is 178.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 180.0\n",
            "now epsilon is 0.01, the reward is 169.0\n",
            "now epsilon is 0.01, the reward is 151.0\n",
            "now epsilon is 0.01, the reward is 165.0\n",
            "now epsilon is 0.01, the reward is 170.0\n",
            "now epsilon is 0.01, the reward is 176.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 153.0\n",
            "now epsilon is 0.01, the reward is 190.0\n",
            "now epsilon is 0.01, the reward is 163.0\n",
            "now epsilon is 0.01, the reward is 148.0\n",
            "now epsilon is 0.01, the reward is 152.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 173.0\n",
            "now epsilon is 0.01, the reward is 156.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 143.0\n",
            "now epsilon is 0.01, the reward is 157.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 149.0\n",
            "now epsilon is 0.01, the reward is 161.0\n",
            "now epsilon is 0.01, the reward is 165.0\n",
            "now epsilon is 0.01, the reward is 189.0\n",
            "now epsilon is 0.01, the reward is 170.0\n",
            "now epsilon is 0.01, the reward is 165.0\n",
            "now epsilon is 0.01, the reward is 156.0\n",
            "now epsilon is 0.01, the reward is 168.0\n",
            "now epsilon is 0.01, the reward is 171.0\n",
            "now epsilon is 0.01, the reward is 189.0\n",
            "now epsilon is 0.01, the reward is 184.0\n",
            "now epsilon is 0.01, the reward is 180.0\n",
            "now epsilon is 0.01, the reward is 158.0\n",
            "now epsilon is 0.01, the reward is 159.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 176.0\n",
            "now epsilon is 0.01, the reward is 194.0\n",
            "now epsilon is 0.01, the reward is 196.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 194.0\n",
            "now epsilon is 0.01, the reward is 152.0\n",
            "now epsilon is 0.01, the reward is 171.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 175.0\n",
            "now epsilon is 0.01, the reward is 187.0\n",
            "now epsilon is 0.01, the reward is 158.0\n",
            "now epsilon is 0.01, the reward is 168.0\n",
            "now epsilon is 0.01, the reward is 178.0\n",
            "now epsilon is 0.01, the reward is 168.0\n",
            "now epsilon is 0.01, the reward is 164.0\n",
            "now epsilon is 0.01, the reward is 191.0\n",
            "Success in epsoide 183, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 176.0\n",
            "now epsilon is 0.01, the reward is 169.0\n",
            "now epsilon is 0.01, the reward is 178.0\n",
            "now epsilon is 0.01, the reward is 156.0\n",
            "now epsilon is 0.01, the reward is 159.0\n",
            "now epsilon is 0.01, the reward is 172.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 157.0\n",
            "now epsilon is 0.01, the reward is 169.0\n",
            "now epsilon is 0.01, the reward is 174.0\n",
            "now epsilon is 0.01, the reward is 168.0\n",
            "now epsilon is 0.01, the reward is 172.0\n",
            "now epsilon is 0.01, the reward is 176.0\n",
            "now epsilon is 0.01, the reward is 166.0\n",
            "now epsilon is 0.01, the reward is 180.0\n",
            "now epsilon is 0.01, the reward is 160.0\n",
            "now epsilon is 0.01, the reward is 174.0\n",
            "now epsilon is 0.01, the reward is 195.0\n",
            "now epsilon is 0.01, the reward is 181.0\n",
            "now epsilon is 0.01, the reward is 179.0\n",
            "Success in epsoide 205, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 188.0\n",
            "Success in epsoide 207, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 208, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 183.0\n",
            "Success in epsoide 210, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 211, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 212, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 170.0\n",
            "now epsilon is 0.01, the reward is 197.0\n",
            "now epsilon is 0.01, the reward is 179.0\n",
            "Success in epsoide 216, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 217, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 193.0\n",
            "now epsilon is 0.01, the reward is 191.0\n",
            "Success in epsoide 220, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 198.0\n",
            "Success in epsoide 222, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 223, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 224, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 225, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 226, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 227, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 228, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 229, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 230, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 231, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 232, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 233, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 234, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 235, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 236, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 237, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 238, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 185.0\n",
            "Success in epsoide 240, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 241, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 188.0\n",
            "now epsilon is 0.01, the reward is 166.0\n",
            "now epsilon is 0.01, the reward is 142.0\n",
            "now epsilon is 0.01, the reward is 143.0\n",
            "now epsilon is 0.01, the reward is 163.0\n",
            "now epsilon is 0.01, the reward is 134.0\n",
            "now epsilon is 0.01, the reward is 98.0\n",
            "now epsilon is 0.01, the reward is 76.0\n",
            "now epsilon is 0.01, the reward is 114.0\n",
            "now epsilon is 0.01, the reward is 122.0\n",
            "now epsilon is 0.01, the reward is 132.0\n",
            "now epsilon is 0.01, the reward is 155.0\n",
            "now epsilon is 0.01, the reward is 130.0\n",
            "now epsilon is 0.01, the reward is 143.0\n",
            "now epsilon is 0.01, the reward is 134.0\n",
            "now epsilon is 0.01, the reward is 135.0\n",
            "now epsilon is 0.01, the reward is 147.0\n",
            "now epsilon is 0.01, the reward is 117.0\n",
            "now epsilon is 0.01, the reward is 144.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 180.0\n",
            "Success in epsoide 263, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 264, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 194.0\n",
            "Success in epsoide 266, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 106.0\n",
            "now epsilon is 0.01, the reward is 125.0\n",
            "now epsilon is 0.01, the reward is 143.0\n",
            "now epsilon is 0.01, the reward is 134.0\n",
            "now epsilon is 0.01, the reward is 157.0\n",
            "now epsilon is 0.01, the reward is 174.0\n",
            "now epsilon is 0.01, the reward is 153.0\n",
            "now epsilon is 0.01, the reward is 165.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 154.0\n",
            "now epsilon is 0.01, the reward is 178.0\n",
            "now epsilon is 0.01, the reward is 165.0\n",
            "now epsilon is 0.01, the reward is 162.0\n",
            "now epsilon is 0.01, the reward is 187.0\n",
            "now epsilon is 0.01, the reward is 184.0\n",
            "now epsilon is 0.01, the reward is 143.0\n",
            "Success in epsoide 283, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 284, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 192.0\n",
            "Success in epsoide 286, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 287, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 288, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 289, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 290, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 291, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "now epsilon is 0.01, the reward is 153.0\n",
            "now epsilon is 0.01, the reward is 180.0\n",
            "Success in epsoide 294, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 295, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 296, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 297, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 298, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n",
            "Success in epsoide 299, used 199 iterations!\n",
            "now epsilon is 0.01, the reward is 200.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdrMlp--pbj0",
        "colab_type": "text"
      },
      "source": [
        "L'algoritmo è andato a convergenza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Yt2ldNpe-r",
        "colab_type": "text"
      },
      "source": [
        "## Continous Cart Pole con Actor-Critic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-kJ7YLdpyIG",
        "colab_type": "text"
      },
      "source": [
        "### Definizione classe `ContinuousCartPoleEnv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czAnHXcOp00N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Classic cart-pole system implemented by Rich Sutton et al.\n",
        "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
        "permalink: https://perma.cc/C9ZM-652R\n",
        "Continuous version by Ian Danforth\n",
        "\"\"\"\n",
        "\n",
        "from gym import spaces, logger\n",
        "from gym.utils import seeding\n",
        "\n",
        "class ContinuousCartPoleEnv(gym.Env):\n",
        "    metadata = {\n",
        "        'render.modes': ['human', 'rgb_array'],\n",
        "        'video.frames_per_second': 50\n",
        "    }\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gravity = 9.8\n",
        "        self.masscart = 1.0\n",
        "        self.masspole = 0.1\n",
        "        self.total_mass = (self.masspole + self.masscart)\n",
        "        self.length = 0.5  # actually half the pole's length\n",
        "        self.polemass_length = (self.masspole * self.length)\n",
        "        self.force_mag = 30.0\n",
        "        self.tau = 0.02  # seconds between state updates\n",
        "        self.min_action = -1.0\n",
        "        self.max_action = 1.0\n",
        "\n",
        "        # Angle at which to fail the episode\n",
        "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
        "        self.x_threshold = 2.4\n",
        "\n",
        "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
        "        # is still within bounds\n",
        "        high = np.array([\n",
        "            self.x_threshold * 2,\n",
        "            np.finfo(np.float32).max,\n",
        "            self.theta_threshold_radians * 2,\n",
        "            np.finfo(np.float32).max])\n",
        "\n",
        "        self.action_space = spaces.Box(\n",
        "            low=self.min_action,\n",
        "            high=self.max_action,\n",
        "            shape=(1,)\n",
        "        )\n",
        "        self.observation_space = spaces.Box(-high, high)\n",
        "\n",
        "        self.seed()\n",
        "        self.viewer = None\n",
        "        self.state = None\n",
        "\n",
        "        self.steps_beyond_done = None\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def stepPhysics(self, force):\n",
        "        x, x_dot, theta, theta_dot = self.state\n",
        "        costheta = math.cos(theta)\n",
        "        sintheta = math.sin(theta)\n",
        "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
        "        thetaacc = (self.gravity * sintheta - costheta * temp) / \\\n",
        "            (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
        "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
        "        x = x + self.tau * x_dot\n",
        "        x_dot = x_dot + self.tau * xacc\n",
        "        theta = theta + self.tau * theta_dot\n",
        "        theta_dot = theta_dot + self.tau * thetaacc\n",
        "        return (x, x_dot, theta, theta_dot)\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action), \\\n",
        "            \"%r (%s) invalid\" % (action, type(action))\n",
        "        # Cast action to float to strip np trappings\n",
        "        force = self.force_mag * float(action)\n",
        "        self.state = self.stepPhysics(force)\n",
        "        x, x_dot, theta, theta_dot = self.state\n",
        "        done = x < -self.x_threshold \\\n",
        "            or x > self.x_threshold \\\n",
        "            or theta < -self.theta_threshold_radians \\\n",
        "            or theta > self.theta_threshold_radians\n",
        "        done = bool(done)\n",
        "\n",
        "        if not done:\n",
        "            reward = 1.0\n",
        "        elif self.steps_beyond_done is None:\n",
        "            # Pole just fell!\n",
        "            self.steps_beyond_done = 0\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            if self.steps_beyond_done == 0:\n",
        "                logger.warn(\"\"\"\n",
        "You are calling 'step()' even though this environment has already returned\n",
        "done = True. You should always call 'reset()' once you receive 'done = True'\n",
        "Any further steps are undefined behavior.\n",
        "                \"\"\")\n",
        "            self.steps_beyond_done += 1\n",
        "            reward = 0.0\n",
        "\n",
        "        return np.array(self.state), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
        "        self.steps_beyond_done = None\n",
        "        return np.array(self.state)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        screen_width = 600\n",
        "        screen_height = 400\n",
        "\n",
        "        world_width = self.x_threshold * 2\n",
        "        scale = screen_width /world_width\n",
        "        carty = 100  # TOP OF CART\n",
        "        polewidth = 10.0\n",
        "        polelen = scale * 1.0\n",
        "        cartwidth = 50.0\n",
        "        cartheight = 30.0\n",
        "\n",
        "        if self.viewer is None:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
        "            l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2\n",
        "            axleoffset = cartheight / 4.0\n",
        "            cart = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
        "            self.carttrans = rendering.Transform()\n",
        "            cart.add_attr(self.carttrans)\n",
        "            self.viewer.add_geom(cart)\n",
        "            l, r, t, b = -polewidth / 2, polewidth / 2, polelen-polewidth / 2, -polewidth / 2\n",
        "            pole = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
        "            pole.set_color(.8, .6, .4)\n",
        "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
        "            pole.add_attr(self.poletrans)\n",
        "            pole.add_attr(self.carttrans)\n",
        "            self.viewer.add_geom(pole)\n",
        "            self.axle = rendering.make_circle(polewidth / 2)\n",
        "            self.axle.add_attr(self.poletrans)\n",
        "            self.axle.add_attr(self.carttrans)\n",
        "            self.axle.set_color(.5, .5, .8)\n",
        "            self.viewer.add_geom(self.axle)\n",
        "            self.track = rendering.Line((0, carty), (screen_width, carty))\n",
        "            self.track.set_color(0, 0, 0)\n",
        "            self.viewer.add_geom(self.track)\n",
        "\n",
        "        if self.state is None:\n",
        "            return None\n",
        "\n",
        "        x = self.state\n",
        "        cartx = x[0] * scale + screen_width / 2.0  # MIDDLE OF CART\n",
        "        self.carttrans.set_translation(cartx, carty)\n",
        "        self.poletrans.set_rotation(-x[2])\n",
        "\n",
        "        return self.viewer.render(return_rgb_array=(mode == 'rgb_array'))\n",
        "\n",
        "    def close(self):\n",
        "        if self.viewer:\n",
        "            self.viewer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt1nCSzZqK8f",
        "colab_type": "text"
      },
      "source": [
        "### Reti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO8s5_uGpidw",
        "colab_type": "code",
        "outputId": "4d0c955f-8e80-4595-bfd8-054933436e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import math\n",
        "env = ContinuousCartPoleEnv()  # Create the environment\n",
        "env.seed(seed)\n",
        "\n",
        "# Modello Actor-Critic \n",
        "num_inputs = env.observation_space.shape[0]\n",
        "num_hidden = 32\n",
        "\n",
        "inputs = layers.Input(shape=(num_inputs,))\n",
        "x = layers.Dense(num_hidden, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(num_hidden, activation=\"relu\")(x)\n",
        "x = layers.Dense(num_hidden, activation=\"relu\")(x)\n",
        "\n",
        "y = layers.Dense(num_hidden, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(num_hidden, activation=\"relu\")(y)\n",
        "\n",
        "action_mean = layers.Dense(1, activation=\"tanh\")(y)\n",
        "action_std = layers.Dense(1, activation=\"softplus\")(y)\n",
        "critic = layers.Dense(1)(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=[action_mean, action_std, critic])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TXdUDIAtU6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_probability import distributions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhT2iSymv1ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optmizer e Loss\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01) # non è altino?!\n",
        "huber_loss = keras.losses.Huber() #una approssimazione intermedia tra MAE e MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjC6mS3YqI37",
        "colab_type": "code",
        "outputId": "0b6623e5-7a06-43c3-95c1-86a7072a0557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        }
      },
      "source": [
        "# Parametri\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "max_steps_per_episode = 10000\n",
        "eps = np.finfo(np.float32).eps.item() # numero più piccolo per cui 1.0 + eps != 1.0\n",
        "\n",
        "# container utili\n",
        "action_probs_history = []\n",
        "critic_value_history = []\n",
        "rewards_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "\n",
        "results = []\n",
        "results_rr = []\n",
        "\n",
        "while True:  # Run until solved\n",
        "    state = env.reset()  #inzializza l'environment \n",
        "    episode_reward = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            state = tf.convert_to_tensor(state)\n",
        "            state = tf.expand_dims(state, 0) #aggiunge una dimensione (4) -> (1,4) per tf/keras\n",
        "\n",
        "            # dato lo stato la rete predice le probabilità delle azioni e stima i futuri rewards \n",
        "            action_mean, action_std, critic_value = model(state)\n",
        "            action_std = tf.clip_by_value(action_std, 0.01, 1)\n",
        "\n",
        "            tf.print(action_std)\n",
        "            tf.print(action_mean)\n",
        "            print(\"\\n\\n\")\n",
        "            critic_value_history.append(critic_value[0, 0])\n",
        "\n",
        "            # calcola la nuova action sulla base delle probabilità\n",
        "            # estrae l'azione con media e std date dall'actor\n",
        "            action = tf.random.normal((1,), mean=action_mean, stddev=action_std)\n",
        "            action = tf.clip_by_value(action, -1, 1)\n",
        "            action_pdf_log = -tf.math.log(action_std) - tf.math.square(action-action_mean)/(2*tf.math.square(action_std))\n",
        "            action_probs_history.append(action_pdf_log)\n",
        "\n",
        "            # applica la nuova azione\n",
        "            temp = env.step(action[0])\n",
        "            state, reward, done, _ = temp\n",
        "\n",
        "            rewards_history.append(reward)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # aggiorna il running reward \n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "        tf.debugging.check_numerics(running_reward, \"running_reward\")\n",
        "        # calcolo valore atteso per il reward (i.e. le label del critic)\n",
        "        # - At each timestep what was the total reward received after that timestep\n",
        "        # - Rewards in the past are discounted by multiplying them with gamma\n",
        "        # - These are the labels for our critic\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "            tf.debugging.check_numerics(discounted_sum, \"discounted_sum\")\n",
        "\n",
        "        # Normalizzazione\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "\n",
        "        returns = returns.tolist()\n",
        "\n",
        "        # Calcolo delle loss per l'attore e per il critico \n",
        "        history = zip(action_probs_history, critic_value_history, returns)\n",
        "        actor_losses = []\n",
        "        critic_losses = []\n",
        "        for log_prob, value, ret in history:\n",
        "    \n",
        "            # per ogni valore nell'history il critico aveva stimato di avere in futuro un total reward pari a \"value\"\n",
        "            # noi abbiamo intrapreso una data azione con log(prob) = log_prob e abbiamo ricevuto il reward pari a \"ret\"\n",
        "           \n",
        "            # dobbiamo aggiornare l'attore in modo che predica con maggiore probabilità un'azione che porti a più alti \n",
        "            # reward rispetto alle stime del critico \n",
        "\n",
        "            diff = ret - value\n",
        "\n",
        "            actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            critic_loss = huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "\n",
        "            # dobbiamo aggornare il critico in modo che predica una migliore stima dei total reward futuri\n",
        "            critic_losses.append(\n",
        "                huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss_value = sum(actor_losses) + sum(critic_losses)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Clear the loss and reward history\n",
        "        action_probs_history.clear()\n",
        "        critic_value_history.clear()\n",
        "        rewards_history.clear()\n",
        "\n",
        "    # salva dettagli per monitorare il tutto + printout\n",
        "    episode_count += 1\n",
        "    results_rr.append(running_reward)\n",
        "    results.append(episode_reward)\n",
        "    plot_results(results,title='GP Actor-Critic Strategy')\n",
        "    \n",
        "    if running_reward > 195:  # Condizione per cui la task è considerata risolta\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        break\n",
        "\n",
        "#printout dei risultati\n",
        "for episodio in range(episode_count):\n",
        "    if episodio % 10 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(results_rr[episodio], episodio))\n",
        "\n",
        "    if results_rr[episodio] > 195:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episodio))\n",
        "        break"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.588341713]]\n",
            "[[0.03588]]\n",
            "\n",
            "\n",
            "\n",
            "[[0.739442945]]\n",
            "[[0.0131581277]]\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-535ff8ba8237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# applica la nuova azione\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-37b1f9252b90>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m\"%r (%s) invalid\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Cast action to float to strip np trappings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepPhysics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}